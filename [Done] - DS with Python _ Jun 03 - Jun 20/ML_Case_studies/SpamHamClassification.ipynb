{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the spam data collection using pandas\n",
    "spamCollection = pd.read_csv('C:\\\\Users\\\\Vaibhav\\\\Desktop\\\\BA\\\\Datasets\\\\MessageSpamCollection_dataset\\\\SpamCollection\\\\SpamCollection', \n",
    "                sep='\\t', header=None, names=['response', 'message'])\n",
    "#header is none, and putting the names of the columns response and message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore data\n",
    "spamCollection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of   response                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection[:10].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         message                                                            \\\n",
       "           count unique                                                top   \n",
       "response                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    653  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "response       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view using groupby\n",
    "spamCollection.groupby('response').describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response                                            message  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the number of characters in each message\n",
    "spamCollection['length'] = spamCollection['message'].apply(len)\n",
    "spamCollection.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['response', 'message', 'length'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMONSTRATION: HOW TO CLEAN UP 1 MESSAGE\n",
    "Clean up each row in msg col\n",
    "- remove the punctuations by comparing with string.punctuations\n",
    "- join the characters to create words\n",
    "- remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection[\"message\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G',\n",
       " 'o',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 'j',\n",
       " 'u',\n",
       " 'r',\n",
       " 'o',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'p',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'c',\n",
       " 'r',\n",
       " 'a',\n",
       " 'z',\n",
       " 'y',\n",
       " ' ',\n",
       " 'A',\n",
       " 'v',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 'g',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " ' ',\n",
       " 'g',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'l',\n",
       " 'a',\n",
       " ' ',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'C',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 't']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation = [char for char in spamCollection[\"message\"][0] if char not in string.punctuation]\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation_msg = ''.join(no_punctuation) #joins all the strings\n",
    "no_punctuation_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the message in lower case, since all the stopwords in the wordnet lexicon (in nltk library) are present in lowercase\n",
    "#Remove the stop-words from the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'Available',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'Cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [word for word in no_punctuation_msg.split() if word.lower() not in stopwords.words('english')]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get rid of pucturations in string class and Stopwords\n",
    "#creating the following function which can be applied on each email\n",
    "def cleanup_text(msg):\n",
    "    no_punctuation = [char for char in msg if char not in string.punctuation]\n",
    "    no_punctuation_msg = ''.join(no_punctuation) #joins all the strings\n",
    "    return [word for word in no_punctuation_msg.split() if word.lower() not in stopwords.words('english') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just type nltk.downloads() and check the package stopwords in the corpora\n",
    "#download the wordnet for synonyms and antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check if our fn is working\n",
    "spamCollection['message'].head().apply(cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection['message'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=<function cleanup_text at 0x000001D969F1FA60>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "#convert each term into a vector (column) and count the freq. in each msg. \n",
    "#Total Freq will come in .vocabulary_ variable\n",
    "#based on the fit method, transform the data to create the bag of words model\n",
    "# Use analyzer fn to vectorize the data \n",
    "bag_of_words_tfrmr = CountVectorizer(analyzer= cleanup_text).fit(spamCollection['message'])\n",
    "#first cleanup the message text by applying cleanup_text on each message and then fit the method on data\n",
    "#on fitting the countVectorizer class on bag of words \n",
    "print(bag_of_words_tfrmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#print length of bag of words\n",
    "print (len(bag_of_words_tfrmr.vocabulary_))\n",
    "print(type(bag_of_words_tfrmr.vocabulary_)) #it's of class dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go', 2060),\n",
       " ('jurong', 7555),\n",
       " ('point', 8917),\n",
       " ('crazy', 5769),\n",
       " ('Available', 1110)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q. How to check the fiest 5 elements of dictionary\n",
    "d = bag_of_words_tfrmr.vocabulary_\n",
    "list(d.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Go': 2060,\n",
       " 'jurong': 7555,\n",
       " 'point': 8917,\n",
       " 'crazy': 5769,\n",
       " 'Available': 1110,\n",
       " 'bugis': 5218,\n",
       " 'n': 8336,\n",
       " 'great': 6937,\n",
       " 'world': 11163,\n",
       " 'la': 7668}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary comprehension to check the first 5 elements of the dictionary\n",
    "{k: d[k] for k in list(d.keys())[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store bag of words for msg using transform method. This will give us a sparse matrix which has words\n",
    "#in the columns and frequencies in the row corresponding to each email\n",
    "msg_bagofwords = bag_of_words_tfrmr.transform(spamCollection['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 11425)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_bagofwords.shape \n",
    "#it has 11425 words in the cols and 5572 messages in the rows and has the term frequencies for each word in each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 1, 1, 1, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can't check the column names as there are no col names for matrices\n",
    "#to check the 1st row of the non-zero elements of the sparse matrix\n",
    "[msg_bagofwords[3,i] for i in range(11425) if msg_bagofwords[3,i]!=0] \n",
    "#this is a sparse matrix having mostly 0s for memory saving and frequency of the term in this msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in range(3):\n",
    "    for col in range(11425):\n",
    "        if msg_bagofwords[row,col]!=0:\n",
    "            print(msg_bagofwords[row,col])   \n",
    "    print(\"\\n\")\n",
    "#note 3rd email shows some terms having freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply  tfidf transformer and fit bag of words into it\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(msg_bagofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 11425)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2882862016308418,\n",
       " 0.31253856260694546,\n",
       " 0.24203960256420656,\n",
       " 0.31253856260694546,\n",
       " 0.29835184088197164,\n",
       " 0.26870593862526665,\n",
       " 0.24984711892976424,\n",
       " 0.18915557732842803,\n",
       " 0.15158474664662352,\n",
       " 0.1834692413608692,\n",
       " 0.31253856260694546,\n",
       " 0.26403384065473806,\n",
       " 0.17046869292195632,\n",
       " 0.24704652376837993,\n",
       " 0.19073428545061483,\n",
       " 0.23026685592418913]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print shape of the tfidf\n",
    "msg_tfidf = tfidf_transformer.transform(msg_bagofwords)\n",
    "print(msg_tfidf.shape)\n",
    "\n",
    "#Now this matrix has tf and idf \n",
    "#Viewing row 0 of the sparse matrix\n",
    "[msg_tfidf[0,i] for i in range(11425) if msg_tfidf[0,i]!=0]\n",
    "#Tf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used \n",
    "#in information retrieval and text mining. This weight is a statistical measure used to evaluate how important \n",
    "#a word is to a document in a collection or corpus. The importance increases proportionally to the number of \n",
    "#times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training NB model to classify\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#using multinomialNB because GaussianNB does not take sparse matrix as the input\n",
    "X= msg_tfidf\n",
    "y = spamCollection['response']\n",
    "spam_classification_model = MultinomialNB().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrixlib.defmatrix.matrix"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "dense = scipy.sparse.csr_matrix.todense(X)\n",
    "type(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793610911701364"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_classification_model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the model on spamCollection['message'][11]\n",
    "spamCollection['message'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam']\n",
      "\n",
      "Predicted class:  spam\n",
      "Expected class:   spam\n"
     ]
    }
   ],
   "source": [
    "#testing the model on spamCollection['message'][11]\n",
    "#prediction on 11th row of training data\n",
    "message = spamCollection['message'][11]\n",
    "#transforming msg to bag of words sparse matrix\n",
    "bag_of_words_for_message = bag_of_words_tfrmr.transform([message])\n",
    "#transforming msg to tfidf matrix\n",
    "tfidf = tfidf_transformer.transform(bag_of_words_for_message)\n",
    "#making prediction\n",
    "print(spam_classification_model.predict(tfidf))\n",
    "print()\n",
    "print('Predicted class: ', spam_classification_model.predict(tfidf)[0])\n",
    "print('Expected class:  ', spamCollection.response[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
