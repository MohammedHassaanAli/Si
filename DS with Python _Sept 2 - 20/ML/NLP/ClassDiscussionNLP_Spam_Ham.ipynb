{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Wonderful! How are you doing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"India (official name: the Republic of India;[19] Hindi: Bhārat Gaṇarājya) is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[d] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia. Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[20] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[21] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus valley civilisation of the third millennium BCE.[22] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest, unfolding as the language of the Vedas, and recording the dawning of Hinduism in India.[23] The Dravidian languages of India were supplanted in the northern regions.[24] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[25] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[26] Early political consolidations gave rise to the loose-knit Maurya and Gupta empires based in the Ganges basin,[27] their collective era suffused with wide-ranging creativity,[28] but also marked by the declining status of women,[29] and the incorporation of untouchability into an organized system of belief.[e][30] In south India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of southeast Asia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India (official name: the Republic of India;[19] Hindi: Bhārat Gaṇarājya) is a country in South Asia.',\n",
       " 'It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[d] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.',\n",
       " 'Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.',\n",
       " '[20] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.',\n",
       " '[21] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus valley civilisation of the third millennium BCE.',\n",
       " '[22] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest, unfolding as the language of the Vedas, and recording the dawning of Hinduism in India.',\n",
       " '[23] The Dravidian languages of India were supplanted in the northern regions.',\n",
       " '[24] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[25] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.',\n",
       " '[26] Early political consolidations gave rise to the loose-knit Maurya and Gupta empires based in the Ganges basin,[27] their collective era suffused with wide-ranging creativity,[28] but also marked by the declining status of women,[29] and the incorporation of untouchability into an organized system of belief.',\n",
       " '[e][30] In south India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of southeast Asia.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " '(',\n",
       " 'official',\n",
       " 'name',\n",
       " ':',\n",
       " 'the',\n",
       " 'Republic',\n",
       " 'of',\n",
       " 'India',\n",
       " ';',\n",
       " '[',\n",
       " '19',\n",
       " ']',\n",
       " 'Hindi',\n",
       " ':',\n",
       " 'Bhārat',\n",
       " 'Gaṇarājya',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Bounded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'on',\n",
       " 'the',\n",
       " 'south',\n",
       " ',',\n",
       " 'the',\n",
       " 'Arabian',\n",
       " 'Sea',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southwest',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Bay',\n",
       " 'of',\n",
       " 'Bengal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southeast',\n",
       " ',',\n",
       " 'it',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'Pakistan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'west',\n",
       " ';',\n",
       " '[',\n",
       " 'd',\n",
       " ']',\n",
       " 'China',\n",
       " ',',\n",
       " 'Nepal',\n",
       " ',',\n",
       " 'and',\n",
       " 'Bhutan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'north',\n",
       " ';',\n",
       " 'and',\n",
       " 'Bangladesh',\n",
       " 'and',\n",
       " 'Myanmar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " ',',\n",
       " 'India',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vicinity',\n",
       " 'of',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Maldives',\n",
       " ';',\n",
       " 'its',\n",
       " 'Andaman',\n",
       " 'and',\n",
       " 'Nicobar',\n",
       " 'Islands',\n",
       " 'share',\n",
       " 'a',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'with',\n",
       " 'Thailand',\n",
       " 'and',\n",
       " 'Indonesia',\n",
       " '.',\n",
       " 'Modern',\n",
       " 'humans',\n",
       " 'arrived',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'subcontinent',\n",
       " 'from',\n",
       " 'Africa',\n",
       " 'no',\n",
       " 'later',\n",
       " 'than',\n",
       " '55,000',\n",
       " 'years',\n",
       " 'ago',\n",
       " '.',\n",
       " '[',\n",
       " '20',\n",
       " ']',\n",
       " 'Their',\n",
       " 'long',\n",
       " 'occupation',\n",
       " ',',\n",
       " 'initially',\n",
       " 'in',\n",
       " 'varying',\n",
       " 'forms',\n",
       " 'of',\n",
       " 'isolation',\n",
       " 'as',\n",
       " 'hunter-gatherers',\n",
       " ',',\n",
       " 'has',\n",
       " 'made',\n",
       " 'the',\n",
       " 'region',\n",
       " 'highly',\n",
       " 'diverse',\n",
       " ',',\n",
       " 'second',\n",
       " 'only',\n",
       " 'to',\n",
       " 'Africa',\n",
       " 'in',\n",
       " 'human',\n",
       " 'genetic',\n",
       " 'diversity',\n",
       " '.',\n",
       " '[',\n",
       " '21',\n",
       " ']',\n",
       " 'Settled',\n",
       " 'life',\n",
       " 'emerged',\n",
       " 'on',\n",
       " 'the',\n",
       " 'subcontinent',\n",
       " 'in',\n",
       " 'the',\n",
       " 'western',\n",
       " 'margins',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Indus',\n",
       " 'river',\n",
       " 'basin',\n",
       " '9,000',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'evolving',\n",
       " 'gradually',\n",
       " 'into',\n",
       " 'the',\n",
       " 'Indus',\n",
       " 'valley',\n",
       " 'civilisation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'third',\n",
       " 'millennium',\n",
       " 'BCE',\n",
       " '.',\n",
       " '[',\n",
       " '22',\n",
       " ']',\n",
       " 'By',\n",
       " '1200',\n",
       " 'BCE',\n",
       " ',',\n",
       " 'an',\n",
       " 'archaic',\n",
       " 'form',\n",
       " 'of',\n",
       " 'Sanskrit',\n",
       " ',',\n",
       " 'an',\n",
       " 'Indo-European',\n",
       " 'language',\n",
       " ',',\n",
       " 'had',\n",
       " 'diffused',\n",
       " 'into',\n",
       " 'India',\n",
       " 'from',\n",
       " 'the',\n",
       " 'northwest',\n",
       " ',',\n",
       " 'unfolding',\n",
       " 'as',\n",
       " 'the',\n",
       " 'language',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Vedas',\n",
       " ',',\n",
       " 'and',\n",
       " 'recording',\n",
       " 'the',\n",
       " 'dawning',\n",
       " 'of',\n",
       " 'Hinduism',\n",
       " 'in',\n",
       " 'India',\n",
       " '.',\n",
       " '[',\n",
       " '23',\n",
       " ']',\n",
       " 'The',\n",
       " 'Dravidian',\n",
       " 'languages',\n",
       " 'of',\n",
       " 'India',\n",
       " 'were',\n",
       " 'supplanted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'northern',\n",
       " 'regions',\n",
       " '.',\n",
       " '[',\n",
       " '24',\n",
       " ']',\n",
       " 'By',\n",
       " '400',\n",
       " 'BCE',\n",
       " ',',\n",
       " 'stratification',\n",
       " 'and',\n",
       " 'exclusion',\n",
       " 'by',\n",
       " 'caste',\n",
       " 'had',\n",
       " 'emerged',\n",
       " 'within',\n",
       " 'Hinduism',\n",
       " ',',\n",
       " '[',\n",
       " '25',\n",
       " ']',\n",
       " 'and',\n",
       " 'Buddhism',\n",
       " 'and',\n",
       " 'Jainism',\n",
       " 'had',\n",
       " 'arisen',\n",
       " ',',\n",
       " 'proclaiming',\n",
       " 'social',\n",
       " 'orders',\n",
       " 'unlinked',\n",
       " 'to',\n",
       " 'heredity',\n",
       " '.',\n",
       " '[',\n",
       " '26',\n",
       " ']',\n",
       " 'Early',\n",
       " 'political',\n",
       " 'consolidations',\n",
       " 'gave',\n",
       " 'rise',\n",
       " 'to',\n",
       " 'the',\n",
       " 'loose-knit',\n",
       " 'Maurya',\n",
       " 'and',\n",
       " 'Gupta',\n",
       " 'empires',\n",
       " 'based',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Ganges',\n",
       " 'basin',\n",
       " ',',\n",
       " '[',\n",
       " '27',\n",
       " ']',\n",
       " 'their',\n",
       " 'collective',\n",
       " 'era',\n",
       " 'suffused',\n",
       " 'with',\n",
       " 'wide-ranging',\n",
       " 'creativity',\n",
       " ',',\n",
       " '[',\n",
       " '28',\n",
       " ']',\n",
       " 'but',\n",
       " 'also',\n",
       " 'marked',\n",
       " 'by',\n",
       " 'the',\n",
       " 'declining',\n",
       " 'status',\n",
       " 'of',\n",
       " 'women',\n",
       " ',',\n",
       " '[',\n",
       " '29',\n",
       " ']',\n",
       " 'and',\n",
       " 'the',\n",
       " 'incorporation',\n",
       " 'of',\n",
       " 'untouchability',\n",
       " 'into',\n",
       " 'an',\n",
       " 'organized',\n",
       " 'system',\n",
       " 'of',\n",
       " 'belief',\n",
       " '.',\n",
       " '[',\n",
       " 'e',\n",
       " ']',\n",
       " '[',\n",
       " '30',\n",
       " ']',\n",
       " 'In',\n",
       " 'south',\n",
       " 'India',\n",
       " ',',\n",
       " 'the',\n",
       " 'Middle',\n",
       " 'kingdoms',\n",
       " 'exported',\n",
       " 'Dravidian-languages',\n",
       " 'scripts',\n",
       " 'and',\n",
       " 'religious',\n",
       " 'cultures',\n",
       " 'to',\n",
       " 'the',\n",
       " 'kingdoms',\n",
       " 'of',\n",
       " 'southeast',\n",
       " 'Asia',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wonderful', '!', 'How', 'are', 'you', 'doing', '?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence=word_tokenize(sentence) #punctuations are being seperated out - punctuations are consired as sep words with a meaning\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wonderful!', 'How', 'are', 'you', 'doing?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wonderful', 'How', 'are', 'you', 'doing']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token for token in tokenized_sentence if token not in string.punctuation]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamCollection = pd.read_csv(r\"C:\\Users\\Vaibhav\\Desktop\\BA\\Datasets\\MessageSpamCollection_dataset\\SpamCollection\\SpamCollection\", sep = \"\\t\", names=[\"response\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamCollection.response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spamCollection[[\"message\"]]\n",
    "y = spamCollection.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>I donno its in your genes or something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>I anything lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>Wow v v impressed. Have funs shopping!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>HI HUN! IM NOT COMIN 2NITE-TELL EVERY1 IM SORR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>No just send to you. Bec you in temple na.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "5293             I donno its in your genes or something\n",
       "4479                                    I anything lor.\n",
       "2768             Wow v v impressed. Have funs shopping!\n",
       "1249  HI HUN! IM NOT COMIN 2NITE-TELL EVERY1 IM SORR...\n",
       "1661         No just send to you. Bec you in temple na."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean 1 sentence for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI HUN! IM NOT COMIN 2NITE-TELL EVERY1 IM SORRY 4 ME, HOPE U AVA GOODTIME!OLI RANG MELNITE IFINK IT MITE B SORTED,BUT IL EXPLAIN EVERYTHIN ON MON.L8RS.x'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = X_train.iloc[3, 0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HI',\n",
       " 'HUN',\n",
       " '!',\n",
       " 'IM',\n",
       " 'NOT',\n",
       " 'COMIN',\n",
       " '2NITE-TELL',\n",
       " 'EVERY1',\n",
       " 'IM',\n",
       " 'SORRY',\n",
       " '4',\n",
       " 'ME',\n",
       " ',',\n",
       " 'HOPE',\n",
       " 'U',\n",
       " 'AVA',\n",
       " 'GOODTIME',\n",
       " '!',\n",
       " 'OLI',\n",
       " 'RANG',\n",
       " 'MELNITE',\n",
       " 'IFINK',\n",
       " 'IT',\n",
       " 'MITE',\n",
       " 'B',\n",
       " 'SORTED',\n",
       " ',',\n",
       " 'BUT',\n",
       " 'IL',\n",
       " 'EXPLAIN',\n",
       " 'EVERYTHIN',\n",
       " 'ON',\n",
       " 'MON.L8RS.x']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HI',\n",
       " 'HUN',\n",
       " 'IM',\n",
       " 'NOT',\n",
       " 'COMIN',\n",
       " '2NITE-TELL',\n",
       " 'EVERY1',\n",
       " 'IM',\n",
       " 'SORRY',\n",
       " '4',\n",
       " 'ME',\n",
       " 'HOPE',\n",
       " 'U',\n",
       " 'AVA',\n",
       " 'GOODTIME',\n",
       " 'OLI',\n",
       " 'RANG',\n",
       " 'MELNITE',\n",
       " 'IFINK',\n",
       " 'IT',\n",
       " 'MITE',\n",
       " 'B',\n",
       " 'SORTED',\n",
       " 'BUT',\n",
       " 'IL',\n",
       " 'EXPLAIN',\n",
       " 'EVERYTHIN',\n",
       " 'ON',\n",
       " 'MON.L8RS.x']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in tokens if token not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'I', ' ', 'H', 'U', 'N', ' ', 'I', 'M', ' ', 'N', 'O', 'T', ' ', 'C', 'O', 'M', 'I', 'N', ' ', '2', 'N', 'I', 'T', 'E', 'T', 'E', 'L', 'L', ' ', 'E', 'V', 'E', 'R', 'Y', '1', ' ', 'I', 'M', ' ', 'S', 'O', 'R', 'R', 'Y', ' ', '4', ' ', 'M', 'E', ' ', 'H', 'O', 'P', 'E', ' ', 'U', ' ', 'A', 'V', 'A', ' ', 'G', 'O', 'O', 'D', 'T', 'I', 'M', 'E', 'O', 'L', 'I', ' ', 'R', 'A', 'N', 'G', ' ', 'M', 'E', 'L', 'N', 'I', 'T', 'E', ' ', 'I', 'F', 'I', 'N', 'K', ' ', 'I', 'T', ' ', 'M', 'I', 'T', 'E', ' ', 'B', ' ', 'S', 'O', 'R', 'T', 'E', 'D', 'B', 'U', 'T', ' ', 'I', 'L', ' ', 'E', 'X', 'P', 'L', 'A', 'I', 'N', ' ', 'E', 'V', 'E', 'R', 'Y', 'T', 'H', 'I', 'N', ' ', 'O', 'N', ' ', 'M', 'O', 'N', 'L', '8', 'R', 'S', 'x']\n"
     ]
    }
   ],
   "source": [
    "p = [char for char in sentence if char not in string.punctuation]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI HUN IM NOT COMIN 2NITETELL EVERY1 IM SORRY 4 ME HOPE U AVA GOODTIMEOLI RANG MELNITE IFINK IT MITE B SORTEDBUT IL EXPLAIN EVERYTHIN ON MONL8RSx'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\".join(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(fileids=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI HUN IM NOT COMIN 2NITETELL EVERY1 IM SORRY 4 ME HOPE U AVA GOODTIMEOLI RANG MELNITE IFINK IT MITE B SORTEDBUT IL EXPLAIN EVERYTHIN ON MONL8RSx'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc=[word.lower() for word in p.split() if word.lower() not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'hun',\n",
       " 'im',\n",
       " 'comin',\n",
       " '2nitetell',\n",
       " 'every1',\n",
       " 'im',\n",
       " 'sorry',\n",
       " '4',\n",
       " 'hope',\n",
       " 'u',\n",
       " 'ava',\n",
       " 'goodtimeoli',\n",
       " 'rang',\n",
       " 'melnite',\n",
       " 'ifink',\n",
       " 'mite',\n",
       " 'b',\n",
       " 'sortedbut',\n",
       " 'il',\n",
       " 'explain',\n",
       " 'everythin',\n",
       " 'monl8rsx']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a fn which can be applied over each of the emails / row of my df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation + '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(sentence):\n",
    "    p = [char for char in sentence if char not in string.punctuation+'0123456789']\n",
    "    p = \"\".join(p)\n",
    "    clean_tokens=[word.lower() for word in p.split() if word.lower() not in stopwords.words(\"english\")]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI HUN! IM NOT COMIN 2NITE-TELL EVERY1 IM SORRY 4 ME, HOPE U AVA GOODTIME!OLI RANG MELNITE IFINK IT MITE B SORTED,BUT IL EXPLAIN EVERYTHIN ON MON.L8RS.x'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'hun',\n",
       " 'im',\n",
       " 'comin',\n",
       " 'nitetell',\n",
       " 'every',\n",
       " 'im',\n",
       " 'sorry',\n",
       " 'hope',\n",
       " 'u',\n",
       " 'ava',\n",
       " 'goodtimeoli',\n",
       " 'rang',\n",
       " 'melnite',\n",
       " 'ifink',\n",
       " 'mite',\n",
       " 'b',\n",
       " 'sortedbut',\n",
       " 'il',\n",
       " 'explain',\n",
       " 'everythin',\n",
       " 'monlrsx']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_text(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(analyzer = cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function cleanup_text at 0x000001989EF8B730>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.fit(X_train.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donno': 1655,\n",
       " 'genes': 2361,\n",
       " 'something': 5673,\n",
       " 'anything': 250,\n",
       " 'lor': 3536,\n",
       " 'wow': 7031,\n",
       " 'v': 6650,\n",
       " 'impressed': 2931,\n",
       " 'funs': 2301,\n",
       " 'shopping': 5473,\n",
       " 'hi': 2697,\n",
       " 'hun': 2842,\n",
       " 'im': 2912,\n",
       " 'comin': 1151,\n",
       " 'nitetell': 4138,\n",
       " 'every': 1914,\n",
       " 'sorry': 5702,\n",
       " 'hope': 2772,\n",
       " 'u': 6509,\n",
       " 'ava': 394,\n",
       " 'goodtimeoli': 2456,\n",
       " 'rang': 4941,\n",
       " 'melnite': 3763,\n",
       " 'ifink': 2896,\n",
       " 'mite': 3858,\n",
       " 'b': 419,\n",
       " 'sortedbut': 5708,\n",
       " 'il': 2906,\n",
       " 'explain': 1968,\n",
       " 'everythin': 1922,\n",
       " 'monlrsx': 3912,\n",
       " 'send': 5373,\n",
       " 'bec': 512,\n",
       " 'temple': 6150,\n",
       " 'na': 4024,\n",
       " 'used': 6621,\n",
       " 'agents': 116,\n",
       " 'dont': 1656,\n",
       " 'drop': 1716,\n",
       " 'since': 5536,\n",
       " 'ive': 3074,\n",
       " 'booked': 659,\n",
       " 'things': 6229,\n",
       " 'year': 7149,\n",
       " 'whole': 6905,\n",
       " 'boston': 675,\n",
       " 'nyc': 4229,\n",
       " 'experiment': 1963,\n",
       " 'talking': 6083,\n",
       " 'mobile': 3880,\n",
       " 'mths': 3975,\n",
       " 'update': 6585,\n",
       " 'latest': 3359,\n",
       " 'orange': 4343,\n",
       " 'cameravideo': 858,\n",
       " 'phones': 4551,\n",
       " 'free': 2231,\n",
       " 'save': 5284,\n",
       " '£s': 7246,\n",
       " 'textsweekend': 6181,\n",
       " 'calls': 848,\n",
       " 'text': 6171,\n",
       " 'yes': 7160,\n",
       " 'callback': 829,\n",
       " 'orno': 4358,\n",
       " 'opt': 4335,\n",
       " 'thanks': 6188,\n",
       " 'ringtone': 5157,\n",
       " 'order': 4348,\n",
       " 'ref': 5018,\n",
       " 'number': 4215,\n",
       " 'k': 3188,\n",
       " 'charged': 972,\n",
       " '£': 7235,\n",
       " 'tone': 6353,\n",
       " 'arrive': 324,\n",
       " 'please': 4613,\n",
       " 'call': 828,\n",
       " 'customer': 1355,\n",
       " 'services': 5397,\n",
       " 'ok': 4281,\n",
       " 'wif': 6916,\n",
       " 'cos': 1255,\n",
       " 'like': 3442,\n",
       " 'try': 6456,\n",
       " 'new': 4102,\n",
       " 'scared': 5299,\n",
       " 'dun': 1738,\n",
       " 'mah': 3638,\n",
       " 'said': 5239,\n",
       " 'loud': 3555,\n",
       " 'email': 1821,\n",
       " 'address': 67,\n",
       " 'changed': 964,\n",
       " 'looking': 3528,\n",
       " 'really': 4978,\n",
       " 'appreciate': 279,\n",
       " 'freemsg': 2237,\n",
       " 'baby': 426,\n",
       " 'got': 2463,\n",
       " 'cam': 854,\n",
       " 'moby': 3887,\n",
       " 'wanna': 6782,\n",
       " 'c': 814,\n",
       " 'hot': 2791,\n",
       " 'pic': 4559,\n",
       " 'fancy': 2022,\n",
       " 'chatim': 984,\n",
       " 'win': 6928,\n",
       " 'utxt': 6639,\n",
       " 'rply': 5199,\n",
       " 'chat': 983,\n",
       " 'hlp': 2723,\n",
       " 'msgp': 3964,\n",
       " 'rcv': 4956,\n",
       " 'finished': 2112,\n",
       " 'missing': 3848,\n",
       " 'plenty': 4618,\n",
       " 'outbid': 4373,\n",
       " 'simonwatson': 5531,\n",
       " 'shinco': 5449,\n",
       " 'dvd': 1746,\n",
       " 'plyr': 4628,\n",
       " 'bid': 570,\n",
       " 'visit': 6716,\n",
       " 'sms': 5634,\n",
       " 'acsmsrewards': 47,\n",
       " 'end': 1836,\n",
       " 'notifications': 4188,\n",
       " 'reply': 5081,\n",
       " 'natalie': 4046,\n",
       " 'f': 1985,\n",
       " 'inviting': 3018,\n",
       " 'friend': 2256,\n",
       " 'see': 5348,\n",
       " 'wwwsmsacunataliek': 7096,\n",
       " 'stop': 5877,\n",
       " 'frnd': 2266,\n",
       " 'r': 4917,\n",
       " 'many': 3671,\n",
       " 'modelsony': 3890,\n",
       " 'ericson': 1873,\n",
       " 'also': 181,\n",
       " 'der': 1499,\n",
       " 'ltgt': 3590,\n",
       " 'luks': 3602,\n",
       " 'good': 2442,\n",
       " 'bt': 762,\n",
       " 'forgot': 2196,\n",
       " 'modl': 3891,\n",
       " 'entry': 1866,\n",
       " 'wkly': 6968,\n",
       " 'comp': 1158,\n",
       " 'fa': 1986,\n",
       " 'cup': 1343,\n",
       " 'final': 2098,\n",
       " 'tkts': 6310,\n",
       " 'st': 5804,\n",
       " 'may': 3721,\n",
       " 'receive': 4994,\n",
       " 'questionstd': 4905,\n",
       " 'txt': 6495,\n",
       " 'ratetcs': 4946,\n",
       " 'apply': 274,\n",
       " 'overs': 4388,\n",
       " 'av': 393,\n",
       " 'wil': 6923,\n",
       " 'use': 6620,\n",
       " 'oneta': 4305,\n",
       " 'oh': 4275,\n",
       " 'outside': 4379,\n",
       " 'players': 4606,\n",
       " 'allowed': 169,\n",
       " 'play': 4603,\n",
       " 'know': 3284,\n",
       " 'yagoing': 7137,\n",
       " 'restaurant': 5116,\n",
       " 'thank': 6187,\n",
       " 'princess': 4784,\n",
       " 'sexy': 5410,\n",
       " 'yep': 7158,\n",
       " 'dereks': 1501,\n",
       " 'house': 2798,\n",
       " 'sunday': 5986,\n",
       " 'lt': 3585,\n",
       " 'uncle': 6535,\n",
       " 'abbey': 5,\n",
       " 'happy': 2602,\n",
       " 'abiola': 10,\n",
       " 'yeah': 7147,\n",
       " 'probably': 4802,\n",
       " 'earlier': 1753,\n",
       " 'costa': 1258,\n",
       " 'del': 1470,\n",
       " 'sol': 5660,\n",
       " 'holiday': 2744,\n",
       " 'await': 407,\n",
       " 'collection': 1132,\n",
       " 'toclaim': 6324,\n",
       " 'sae': 5233,\n",
       " 'tc': 6111,\n",
       " 'pobox': 4641,\n",
       " 'stockport': 5870,\n",
       " 'skxh': 5577,\n",
       " 'cost£pm': 1264,\n",
       " 'maxmins': 3718,\n",
       " 'die': 1545,\n",
       " 'want': 6783,\n",
       " 'stuffs': 5933,\n",
       " 'haf': 2560,\n",
       " 'eaten': 1769,\n",
       " 'wat': 6802,\n",
       " 'time': 6286,\n",
       " 'wan': 6780,\n",
       " 'come': 1144,\n",
       " 'wlcome': 6972,\n",
       " 'back': 431,\n",
       " 'wonder': 6986,\n",
       " 'lion': 3462,\n",
       " 'nothing': 4185,\n",
       " 'much': 3978,\n",
       " 'dizzamn': 1609,\n",
       " 'aight': 136,\n",
       " 'ill': 2908,\n",
       " 'ask': 339,\n",
       " 'suitemates': 5978,\n",
       " 'get': 2370,\n",
       " 'matter': 3710,\n",
       " 'mind': 3819,\n",
       " 'saying': 5291,\n",
       " 'pack': 4406,\n",
       " 'buy': 799,\n",
       " 'storelike': 5889,\n",
       " 'cereals': 949,\n",
       " 'must': 4006,\n",
       " 'food': 2179,\n",
       " 'gari': 2330,\n",
       " 'ja': 3087,\n",
       " 'miss': 3844,\n",
       " 'records': 5007,\n",
       " 'indicate': 2959,\n",
       " 'maybe': 3723,\n",
       " 'entitled': 1864,\n",
       " 'pounds': 4710,\n",
       " 'compensation': 1163,\n",
       " 'accident': 29,\n",
       " 'claim': 1065,\n",
       " 'msg': 3962,\n",
       " 'congratulations': 1206,\n",
       " 'ur': 6604,\n",
       " 'awarded': 411,\n",
       " 'cd': 933,\n",
       " 'vouchers': 6736,\n",
       " 'gift': 2385,\n",
       " 'guaranteed': 2529,\n",
       " 'draw': 1693,\n",
       " 'music': 4004,\n",
       " 'g': 2307,\n",
       " 'wants': 6787,\n",
       " 'fuck': 2282,\n",
       " 'persons': 4530,\n",
       " 'story': 5891,\n",
       " 'bank': 459,\n",
       " 'say': 5288,\n",
       " 'money': 3907,\n",
       " 'someone': 5666,\n",
       " 'conacted': 1184,\n",
       " 'dating': 1408,\n",
       " 'service': 5396,\n",
       " 'entered': 1860,\n",
       " 'phone': 4548,\n",
       " 'youto': 7201,\n",
       " 'find': 2102,\n",
       " 'landline': 3332,\n",
       " 'poboxntf': 4643,\n",
       " 'make': 3649,\n",
       " 'love': 3560,\n",
       " 'times': 6290,\n",
       " 'per': 4511,\n",
       " 'night': 4121,\n",
       " 'thats': 6195,\n",
       " 'problem': 4803,\n",
       " 'oops': 4321,\n",
       " 'hey': 2691,\n",
       " 'babe': 423,\n",
       " 'didnt': 1540,\n",
       " 'sooner': 5693,\n",
       " 'gary': 2332,\n",
       " 'fix': 2128,\n",
       " 'cause': 927,\n",
       " 'thinks': 6234,\n",
       " 'knows': 3289,\n",
       " 'doesnt': 1628,\n",
       " 'go': 2414,\n",
       " 'far': 2027,\n",
       " 'ptbo': 4856,\n",
       " 'says': 5292,\n",
       " 'cost': 1257,\n",
       " 'bucks': 770,\n",
       " 'might': 3807,\n",
       " 'cheaper': 989,\n",
       " 'second': 5337,\n",
       " 'hand': 2578,\n",
       " 'machines': 3623,\n",
       " 'right': 5149,\n",
       " 'let': 3415,\n",
       " 'vldo': 6724,\n",
       " 'adsense': 85,\n",
       " 'approved': 284,\n",
       " 'nice': 4113,\n",
       " 'juicy': 3171,\n",
       " 'booty': 666,\n",
       " 'way': 6817,\n",
       " 'omg': 4297,\n",
       " 'joanna': 3137,\n",
       " 'freaking': 2228,\n",
       " 'shes': 5443,\n",
       " 'looked': 3526,\n",
       " 'thru': 6263,\n",
       " 'friends': 2257,\n",
       " 'photos': 4554,\n",
       " 'asking': 343,\n",
       " 'stuff': 5928,\n",
       " 'myspace': 4020,\n",
       " 'havent': 2621,\n",
       " 'even': 1907,\n",
       " 'logged': 3503,\n",
       " 'prize': 4795,\n",
       " 'another': 230,\n",
       " 'wwwtcbiz': 7098,\n",
       " 'pmin': 4632,\n",
       " 'polo': 4663,\n",
       " 'ltd': 3586,\n",
       " 'suite': 5977,\n",
       " 'london': 3517,\n",
       " 'wj': 6963,\n",
       " 'hl': 2721,\n",
       " 'busy': 795,\n",
       " 'charge': 971,\n",
       " 'camera': 857,\n",
       " 'hellogorgeous': 2662,\n",
       " 'hows': 2807,\n",
       " 'fone': 2175,\n",
       " 'lst': 3584,\n",
       " 'nitw': 4140,\n",
       " 'wen': 6865,\n",
       " 'texd': 6170,\n",
       " 'hopeu': 2779,\n",
       " 'ad': 60,\n",
       " 'wkend': 6965,\n",
       " 'sure': 6010,\n",
       " 'lookin': 3527,\n",
       " 'ward': 6789,\n",
       " 'cin': 1058,\n",
       " 'mrw': 3960,\n",
       " 'luv': 3607,\n",
       " 'jaz': 3112,\n",
       " 'still': 5865,\n",
       " 'working': 7005,\n",
       " 'tried': 6438,\n",
       " 'adding': 66,\n",
       " 'zeros': 7226,\n",
       " 'savings': 5286,\n",
       " 'checking': 997,\n",
       " 'always': 187,\n",
       " 'excuse': 1944,\n",
       " 'city': 1062,\n",
       " 'sent': 5382,\n",
       " 'gam': 2318,\n",
       " 'gone': 2438,\n",
       " 'outstanding': 4382,\n",
       " 'innings': 2981,\n",
       " 'believe': 538,\n",
       " 'e': 1750,\n",
       " 'person': 4524,\n",
       " 'whos': 6907,\n",
       " 'survey': 6020,\n",
       " 'pussy': 4882,\n",
       " 'perfect': 4514,\n",
       " 'hit': 2715,\n",
       " 'move': 3947,\n",
       " 'hear': 2639,\n",
       " 'nope': 4169,\n",
       " 'meanwhile': 3739,\n",
       " 'talk': 6080,\n",
       " 'greet': 2502,\n",
       " 'thanx': 6190,\n",
       " 'lot': 3545,\n",
       " 'sun': 5985,\n",
       " 'anti': 241,\n",
       " 'sleep': 5585,\n",
       " 'medicine': 3746,\n",
       " 'rite': 5166,\n",
       " 'well': 6861,\n",
       " 'best': 555,\n",
       " 'mate': 3701,\n",
       " 'pete': 4534,\n",
       " 'went': 6867,\n",
       " 'week': 6843,\n",
       " 'geva': 2380,\n",
       " 'longer': 3521,\n",
       " 'sen': 5372,\n",
       " 'kind': 3252,\n",
       " 'advice': 90,\n",
       " 'thk': 6237,\n",
       " 'hint': 2710,\n",
       " 'forum': 2208,\n",
       " 'already': 175,\n",
       " 'told': 6339,\n",
       " 'ron': 5183,\n",
       " 'n': 4023,\n",
       " 'darren': 1400,\n",
       " 'going': 2430,\n",
       " 'tell': 6142,\n",
       " 'shuhui': 5505,\n",
       " 'yup': 7217,\n",
       " 'lunch': 3604,\n",
       " 'buffet': 776,\n",
       " 'eat': 1768,\n",
       " 'chatting': 987,\n",
       " 'guys': 2549,\n",
       " 'movies': 3951,\n",
       " 'side': 5514,\n",
       " 'buzy': 804,\n",
       " 'feel': 2056,\n",
       " 'belly': 543,\n",
       " 'warm': 6790,\n",
       " 'wish': 6949,\n",
       " 'shall': 5425,\n",
       " 'meet': 3748,\n",
       " 'dreams': 1699,\n",
       " 'ahmad': 129,\n",
       " 'adoring': 80,\n",
       " 'kiss': 3258,\n",
       " 'wake': 6762,\n",
       " 'gt': 2525,\n",
       " 'either': 1805,\n",
       " 'ideas': 2889,\n",
       " 'anyplaces': 247,\n",
       " 'yo': 7178,\n",
       " 'work': 7002,\n",
       " 'doinghow': 1640,\n",
       " 'fb': 2048,\n",
       " 'couple': 1275,\n",
       " 'minutes': 3836,\n",
       " 'ü': 7250,\n",
       " 'attending': 369,\n",
       " 'da': 1370,\n",
       " 'talks': 6084,\n",
       " 'help': 2666,\n",
       " 'propose': 4839,\n",
       " 'tomorrow': 6350,\n",
       " 'depends': 1493,\n",
       " 'quality': 4897,\n",
       " 'type': 6506,\n",
       " 'boye': 694,\n",
       " 'faded': 1995,\n",
       " 'glory': 2408,\n",
       " 'ralphs': 4935,\n",
       " 'bill': 576,\n",
       " 'letters': 3418,\n",
       " 'i’m': 3085,\n",
       " 'expecting': 1959,\n",
       " 'one': 4302,\n",
       " 'isn’t': 3044,\n",
       " 'home': 2750,\n",
       " 'sale': 5244,\n",
       " 'except': 1940,\n",
       " 'theres': 6216,\n",
       " 'chick': 1018,\n",
       " 'huge': 2836,\n",
       " 'boobs': 657,\n",
       " 'ha': 2555,\n",
       " 'jus': 3181,\n",
       " 'ate': 357,\n",
       " 'honey': 2761,\n",
       " 'ar': 292,\n",
       " 'sweet': 6032,\n",
       " 'shld': 5465,\n",
       " 'ya': 7136,\n",
       " 'wana': 6781,\n",
       " 'lessons': 3414,\n",
       " 'haha': 2561,\n",
       " 'stretch': 5902,\n",
       " 'chance': 961,\n",
       " 'cash': 911,\n",
       " 'wk': 6964,\n",
       " 'action': 52,\n",
       " 'tscs': 6462,\n",
       " 'wwwmovietriviatv': 7085,\n",
       " 'custcare': 1353,\n",
       " 'xpwk': 7117,\n",
       " 'urgent': 6606,\n",
       " 'bonus': 655,\n",
       " 'caller': 834,\n",
       " 'nd': 4060,\n",
       " 'attempt': 366,\n",
       " 'contact': 1218,\n",
       " 'boxqu': 691,\n",
       " 'national': 4048,\n",
       " 'rate': 4944,\n",
       " 'join': 3146,\n",
       " 'sts': 5916,\n",
       " 'later': 3358,\n",
       " 'meeting': 3751,\n",
       " 'five': 2127,\n",
       " 'class': 1072,\n",
       " 'messagesome': 3793,\n",
       " 'sendername': 5375,\n",
       " 'sentdate': 5383,\n",
       " 'everything': 1923,\n",
       " 'via': 6687,\n",
       " 'fullonsmscom': 2293,\n",
       " 'shag': 5419,\n",
       " 'dointerested': 1643,\n",
       " 'sextextukcom': 5409,\n",
       " 'xxuk': 7122,\n",
       " 'suzy': 6022,\n",
       " 'txts': 6502,\n",
       " 'tncs': 6319,\n",
       " 'website': 6832,\n",
       " 'x': 7108,\n",
       " 'dear': 1436,\n",
       " 'heroi': 2681,\n",
       " 'leaving': 3390,\n",
       " 'qatar': 4893,\n",
       " 'tonite': 6363,\n",
       " 'apt': 290,\n",
       " 'opportunitypls': 4332,\n",
       " 'keep': 3220,\n",
       " 'touch': 6392,\n",
       " 'ltemailgt': 3589,\n",
       " 'kerala': 3227,\n",
       " 'sipix': 5546,\n",
       " 'digital': 1559,\n",
       " 'fromm': 2274,\n",
       " 'delivery': 1478,\n",
       " 'within': 6957,\n",
       " 'days': 1421,\n",
       " 'hes': 2686,\n",
       " 'skateboarding': 5567,\n",
       " 'despite': 1511,\n",
       " 'fact': 1993,\n",
       " 'gets': 2374,\n",
       " 'thrown': 6261,\n",
       " 'winds': 6933,\n",
       " 'bandages': 457,\n",
       " 'shit': 5457,\n",
       " 'arms': 314,\n",
       " 'neft': 4079,\n",
       " 'transaction': 6414,\n",
       " 'reference': 5019,\n",
       " 'rs': 5201,\n",
       " 'ltdecimalgt': 3587,\n",
       " 'credited': 1306,\n",
       " 'beneficiary': 550,\n",
       " 'account': 35,\n",
       " 'lttimegt': 3592,\n",
       " 'birthday': 592,\n",
       " 'true': 6447,\n",
       " 'blankets': 609,\n",
       " 'sufficient': 5969,\n",
       " 'thx': 6272,\n",
       " 'think': 6230,\n",
       " 'away': 412,\n",
       " 'trek': 6436,\n",
       " 'long': 3520,\n",
       " 'family': 2016,\n",
       " 'town': 6398,\n",
       " 'photoshop': 4555,\n",
       " 'makes': 3650,\n",
       " 'computer': 1179,\n",
       " 'shut': 5507,\n",
       " 'finishing': 2114,\n",
       " 'soon': 5691,\n",
       " 'familymay': 2017,\n",
       " 'bring': 731,\n",
       " 'happiness': 2601,\n",
       " 'stability': 5805,\n",
       " 'tranquility': 6413,\n",
       " 'vibrant': 6688,\n",
       " 'colourful': 1138,\n",
       " 'life': 3431,\n",
       " 'gonna': 2441,\n",
       " 'ring': 5154,\n",
       " 'weekend': 6844,\n",
       " 'wot': 7024,\n",
       " 'land': 3330,\n",
       " 'line': 3455,\n",
       " 'valid': 6655,\n",
       " 'hrs': 2815,\n",
       " 'sister': 5553,\n",
       " 'cleared': 1080,\n",
       " 'two': 6493,\n",
       " 'round': 5191,\n",
       " 'birla': 588,\n",
       " 'soft': 5656,\n",
       " 'yesterday': 7168,\n",
       " 'nokia': 4157,\n",
       " 'auction': 377,\n",
       " 'take': 6073,\n",
       " 'part': 4450,\n",
       " 'hgsuitelands': 2694,\n",
       " 'rowwjhl': 5197,\n",
       " 'reward': 5138,\n",
       " 'hours': 2797,\n",
       " 'subscribegbpmnth': 5950,\n",
       " 'inc': 2937,\n",
       " 'stoptxtstop': 5886,\n",
       " 'onwards': 4315,\n",
       " 'eve': 1904,\n",
       " 'xy': 7133,\n",
       " 'car': 883,\n",
       " 'picking': 4562,\n",
       " 'bothering': 678,\n",
       " 'trust': 6452,\n",
       " 'answers': 237,\n",
       " 'pls': 4621,\n",
       " 'leave': 3388,\n",
       " 'lar': 3343,\n",
       " 'carry': 906,\n",
       " 'meh': 3755,\n",
       " 'heavy': 2650,\n",
       " 'num': 4214,\n",
       " 'familiar': 2015,\n",
       " 'noi': 4150,\n",
       " 'rumour': 5217,\n",
       " 'apartment': 259,\n",
       " 'chennai': 1007,\n",
       " 'theyre': 6224,\n",
       " 'female': 2067,\n",
       " 'howre': 2806,\n",
       " 'throwing': 6260,\n",
       " 'deciding': 1448,\n",
       " 'okay': 4282,\n",
       " 'screaming': 5321,\n",
       " 'means': 3737,\n",
       " 'shouting': 5486,\n",
       " 'thing': 6228,\n",
       " 'getting': 2378,\n",
       " 'connection': 1208,\n",
       " 'bw': 807,\n",
       " 'nt': 4207,\n",
       " 'joking': 3154,\n",
       " 'seriously': 5394,\n",
       " 'beautiful': 509,\n",
       " 'truth': 6454,\n",
       " 'gravity': 2490,\n",
       " 'read': 4965,\n",
       " 'carefully': 893,\n",
       " 'heart': 2643,\n",
       " 'feels': 2061,\n",
       " 'light': 3438,\n",
       " 'leaves': 3389,\n",
       " 'goodmorning': 2448,\n",
       " 'enjoy': 1852,\n",
       " 'watching': 6807,\n",
       " 'playing': 4610,\n",
       " 'football': 2184,\n",
       " 'basketball': 478,\n",
       " 'outdoors': 4374,\n",
       " 'cashbincouk': 913,\n",
       " 'lots': 3548,\n",
       " 'wwwcashbincouk': 7071,\n",
       " 'welcome': 6859,\n",
       " 'biggest': 574,\n",
       " 'ever': 1913,\n",
       " 'give': 2397,\n",
       " 'heard': 2640,\n",
       " 'bit': 594,\n",
       " 'crowd': 1320,\n",
       " 'great': 2494,\n",
       " 'cardiff': 885,\n",
       " 'popping': 4683,\n",
       " 'ibuprofens': 2878,\n",
       " 'italian': 3048,\n",
       " 'would': 7028,\n",
       " 'else': 1817,\n",
       " 'instead': 2993,\n",
       " 'todaysundaysunday': 6330,\n",
       " 'holidayso': 2745,\n",
       " 'holla': 2746,\n",
       " 'done': 1653,\n",
       " 'next': 4109,\n",
       " 'space': 5726,\n",
       " 'gives': 2399,\n",
       " 'remember': 5052,\n",
       " 'furniture': 2302,\n",
       " 'around': 318,\n",
       " 'lock': 3499,\n",
       " 'locks': 3500,\n",
       " 'key': 3231,\n",
       " 'jenne': 3121,\n",
       " 'check': 993,\n",
       " 'choose': 1046,\n",
       " 'videos': 6696,\n",
       " 'smsshsexnetun': 5636,\n",
       " 'fgkslpopw': 2075,\n",
       " 'fgkslpo': 2074,\n",
       " 'tirupur': 6301,\n",
       " 'day': 1416,\n",
       " 'blastin': 610,\n",
       " 'tsunamis': 6465,\n",
       " 'occur': 4247,\n",
       " 'rajnikant': 4932,\n",
       " 'stopped': 5879,\n",
       " 'swimming': 6039,\n",
       " 'indian': 2957,\n",
       " 'oceand': 4249,\n",
       " 'cant': 873,\n",
       " 'anyone': 245,\n",
       " 'spare': 5732,\n",
       " 'room': 5185,\n",
       " 'top': 6374,\n",
       " 'head': 2627,\n",
       " 'today': 6325,\n",
       " 'excuses': 1946,\n",
       " 'mr': 3956,\n",
       " 'sheffield': 5439,\n",
       " 'game': 2319,\n",
       " 'youre': 7196,\n",
       " 'boss': 674,\n",
       " 'nanny': 4039,\n",
       " 'raise': 4927,\n",
       " 'dave': 1413,\n",
       " 'notice': 4187,\n",
       " 'collect': 1129,\n",
       " 'tenerife': 6154,\n",
       " 'award': 410,\n",
       " 'tcs': 6114,\n",
       " 'box': 687,\n",
       " 'cwwx': 1366,\n",
       " 'ppm': 4720,\n",
       " 'guy': 2548,\n",
       " 'bitching': 596,\n",
       " 'acted': 49,\n",
       " 'id': 2885,\n",
       " 'interested': 3001,\n",
       " 'buying': 802,\n",
       " 'gave': 2337,\n",
       " 'us': 6618,\n",
       " 'mistake': 3854,\n",
       " 'goto': 2467,\n",
       " 'doctor': 1622,\n",
       " 'late': 3353,\n",
       " 'tellmiss': 6144,\n",
       " 'oooh': 4318,\n",
       " 'bed': 518,\n",
       " 'ridden': 5147,\n",
       " 'ey': 1979,\n",
       " 'thinking': 6233,\n",
       " 'changes': 965,\n",
       " 'appendix': 269,\n",
       " 'age': 114,\n",
       " 'range': 4942,\n",
       " 'however': 2805,\n",
       " 'impossible': 2928,\n",
       " 'chill': 1034,\n",
       " 'scores': 5310,\n",
       " 'sophas': 5698,\n",
       " 'secondary': 5338,\n",
       " 'application': 273,\n",
       " 'schools': 5305,\n",
       " 'applying': 276,\n",
       " 'research': 5094,\n",
       " 'joke': 3151,\n",
       " 'ogunrinde': 4274,\n",
       " 'school': 5304,\n",
       " 'less': 3411,\n",
       " 'expensive': 1960,\n",
       " 'ones': 4304,\n",
       " 'backa': 432,\n",
       " 'necklace': 4071,\n",
       " 'token': 6337,\n",
       " 'youthats': 7200,\n",
       " 'wife': 6917,\n",
       " 'likingbe': 3446,\n",
       " 'seeno': 5356,\n",
       " 'thatdont': 6193,\n",
       " 'mei': 3756,\n",
       " 'wait': 6755,\n",
       " 'till': 6284,\n",
       " 'themobhit': 6207,\n",
       " 'link': 3460,\n",
       " 'premium': 4752,\n",
       " 'pink': 4579,\n",
       " 'panther': 4429,\n",
       " 'sugababes': 5970,\n",
       " 'crazy': 1297,\n",
       " 'zebra': 7224,\n",
       " 'animation': 218,\n",
       " 'badass': 436,\n",
       " 'hoody': 2768,\n",
       " 'wallpaperall': 6775,\n",
       " 'height': 2654,\n",
       " 'recycling': 5012,\n",
       " 'twice': 6487,\n",
       " 'people': 4509,\n",
       " 'spend': 5754,\n",
       " 'earning': 1758,\n",
       " 'spent': 5756,\n",
       " 'spending': 5755,\n",
       " 'morning': 3927,\n",
       " 'smiling': 5626,\n",
       " 'mystery': 4021,\n",
       " 'solved': 5663,\n",
       " 'opened': 4323,\n",
       " 'batch': 480,\n",
       " 'isnt': 3041,\n",
       " 'sweetie': 6035,\n",
       " 'evening': 1908,\n",
       " 'banks': 460,\n",
       " 'fees': 2062,\n",
       " 'fixed': 2130,\n",
       " 'better': 561,\n",
       " 'ready': 4968,\n",
       " 'thursday': 6270,\n",
       " 'representative': 5087,\n",
       " 'freephone': 2241,\n",
       " 'ampm': 203,\n",
       " 'forced': 2188,\n",
       " 'slice': 5594,\n",
       " 'hungry': 2846,\n",
       " 'tho': 6244,\n",
       " 'sucks': 5962,\n",
       " 'mark': 3680,\n",
       " 'worried': 7015,\n",
       " 'sick': 5513,\n",
       " 'turn': 6479,\n",
       " 'pizza': 4587,\n",
       " 'lol': 3513,\n",
       " 'bout': 683,\n",
       " 'early': 1756,\n",
       " 'almost': 171,\n",
       " 'noon': 4166,\n",
       " 'promise': 4827,\n",
       " 'youll': 7191,\n",
       " 'made': 3628,\n",
       " 'nothis': 4186,\n",
       " 'kallis': 3198,\n",
       " 'groundamla': 2514,\n",
       " 'durban': 1741,\n",
       " 'sindu': 5538,\n",
       " 'job': 3138,\n",
       " 'blackberry': 602,\n",
       " 'bold': 649,\n",
       " 'torch': 6382,\n",
       " 'plus': 4627,\n",
       " 'wifi': 6921,\n",
       " 'ipad': 3023,\n",
       " 'never': 4098,\n",
       " 'reasons': 4984,\n",
       " 'god': 2419,\n",
       " 'nicenicehow': 4114,\n",
       " 'joys': 3164,\n",
       " 'father': 2035,\n",
       " 'john': 3144,\n",
       " 'ans': 231,\n",
       " 'ths': 6265,\n",
       " 'hav': 2617,\n",
       " 'iq': 3027,\n",
       " 'tis': 6302,\n",
       " 'ias': 2872,\n",
       " 'question': 4902,\n",
       " 'answer': 233,\n",
       " 'apps': 286,\n",
       " 'varaya': 6663,\n",
       " 'elaya': 1809,\n",
       " 'explicitly': 1969,\n",
       " 'nora': 4170,\n",
       " 'bother': 677,\n",
       " 'twenty': 6486,\n",
       " 'past': 4471,\n",
       " 'train': 6408,\n",
       " 'durham': 1742,\n",
       " 'coz': 1284,\n",
       " 'reserved': 5099,\n",
       " 'seat': 5335,\n",
       " 'adult': 86,\n",
       " 'content': 1221,\n",
       " 'video': 6692,\n",
       " 'shortly': 5479,\n",
       " 'alright': 177,\n",
       " 'set': 5400,\n",
       " 'man': 3659,\n",
       " 'glad': 2402,\n",
       " 'claire': 1068,\n",
       " 'goes': 2425,\n",
       " 'petey': 4537,\n",
       " 'boy': 693,\n",
       " 'whereare': 6897,\n",
       " 'friendsare': 2258,\n",
       " 'thekingshead': 6203,\n",
       " 'canlove': 870,\n",
       " 'nic': 4112,\n",
       " 'cool': 1238,\n",
       " 'pool': 4676,\n",
       " 'jacuzzi': 3091,\n",
       " 'gokila': 2431,\n",
       " 'aha': 126,\n",
       " 'trying': 6458,\n",
       " 'todays': 6329,\n",
       " 'shows': 5497,\n",
       " 'congrats': 1205,\n",
       " 'special': 5739,\n",
       " 'cinema': 1060,\n",
       " 'pass': 4461,\n",
       " 'suprman': 6008,\n",
       " 'matrix': 3709,\n",
       " 'starwars': 5833,\n",
       " 'etc': 1895,\n",
       " 'bxipwe': 809,\n",
       " 'pm': 4630,\n",
       " 'prob': 4801,\n",
       " 'grinder': 2505,\n",
       " 'ajith': 146,\n",
       " 'film': 2095,\n",
       " 'ah': 125,\n",
       " 'brah': 701,\n",
       " 'last': 3350,\n",
       " 'exams': 1938,\n",
       " 'messagethanks': 3794,\n",
       " 'using': 6627,\n",
       " 'subscription': 5953,\n",
       " 'pmsgrcvd': 4635,\n",
       " 'skip': 5575,\n",
       " 'unsubscribe': 6579,\n",
       " 'customercare': 1356,\n",
       " 'unintentionally': 6558,\n",
       " 'bad': 435,\n",
       " 'timing': 6293,\n",
       " 'fingers': 2109,\n",
       " 'trains': 6411,\n",
       " 'along': 173,\n",
       " 'fifteen': 2080,\n",
       " 'min': 3817,\n",
       " 'warning': 6793,\n",
       " 'de': 1428,\n",
       " 'start': 5826,\n",
       " 'prepare': 4754,\n",
       " 'need': 4073,\n",
       " 'dunno': 1739,\n",
       " 'lei': 3400,\n",
       " 'dinner': 1569,\n",
       " 'pick': 4560,\n",
       " 'message': 3786,\n",
       " 'awesome': 413,\n",
       " 'mapquest': 3673,\n",
       " 'look': 3524,\n",
       " 'usf': 6625,\n",
       " 'dogwood': 1637,\n",
       " 'drive': 1710,\n",
       " 'tiny': 6295,\n",
       " 'street': 5898,\n",
       " 'parking': 4449,\n",
       " 'whats': 6887,\n",
       " 'name': 4033,\n",
       " 'brison': 735,\n",
       " 'book': 658,\n",
       " 'language': 3338,\n",
       " 'words': 6999,\n",
       " 'impressively': 2933,\n",
       " 'sensible': 5380,\n",
       " 'fine': 2104,\n",
       " 'boring': 670,\n",
       " 'whens': 6895,\n",
       " 'mmmmmm': 3871,\n",
       " 'youso': 7199,\n",
       " 'begin': 533,\n",
       " 'takes': 6076,\n",
       " 'closer': 1095,\n",
       " 'eh': 1799,\n",
       " 'leh': 3399,\n",
       " 'din': 1564,\n",
       " 'sad': 5232,\n",
       " 'tv': 6482,\n",
       " 'office': 4262,\n",
       " 'disturb': 1602,\n",
       " 'liao': 3421,\n",
       " 'flaked': 2134,\n",
       " 'shits': 5461,\n",
       " 'goin': 2428,\n",
       " 'roommate': 5186,\n",
       " 'tonight': 6361,\n",
       " 'knew': 3281,\n",
       " 'saw': 5287,\n",
       " 'dollar': 1646,\n",
       " 'store': 5888,\n",
       " 'search': 5332,\n",
       " 'online': 4308,\n",
       " 'stupid': 5935,\n",
       " 'wont': 6990,\n",
       " 'dad': 1374,\n",
       " 'called': 833,\n",
       " 'brother': 747,\n",
       " 'spoken': 5774,\n",
       " 'easier': 1762,\n",
       " 'holding': 2742,\n",
       " 'knowyetunde': 3292,\n",
       " 'hasnt': 2613,\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_bows = bow.transform(X_train.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7257 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 35714 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_bows.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[msg_bows[3,i] for i in range(msg_bows.shape[1]) if msg_bows[3,i]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(msg_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_score=tfidf.transform(msg_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7257 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35714 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25483491204066877,\n",
       " 0.15557377351426901,\n",
       " 0.21396973013651718,\n",
       " 0.15713934481948516,\n",
       " 0.25483491204066877,\n",
       " 0.24288261254113003,\n",
       " 0.25483491204066877,\n",
       " 0.14295149068312585,\n",
       " 0.14500892998867904,\n",
       " 0.24288261254113003,\n",
       " 0.25483491204066877,\n",
       " 0.21790596821304492,\n",
       " 0.21045790059464758,\n",
       " 0.25483491204066877,\n",
       " 0.22245002158905425,\n",
       " 0.25483491204066877,\n",
       " 0.25483491204066877,\n",
       " 0.24288261254113003,\n",
       " 0.13697596119632638,\n",
       " 0.25483491204066877,\n",
       " 0.08563731012668462]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tfidf_score[3,i] for i in range(tfidf_score.shape[1]) if tfidf_score[3,i]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency\n",
    "Frequency of some word in this email / total frequency of all the terms in this email\n",
    "A word 'cat' has a frequency of 3 in the email 1 and the total number of words in this email = 100. So the term frequency = 3/100. The importance of the word in the email is high if it has  a high term frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Document frequency\n",
    "Let's say there 10 mn documents in our corpus and the word cat appears in 1000 of these documents. IDF = log(10,000000/1000) = 4. A word that is occuring in all the documents is less important because perhaps the entire corpus is discussing about cats. A word that is having high term frequency in 1 email is a very important word for email 1 \n",
    "\n",
    "TFidf score = Tf * idf for that particular word\n",
    "\n",
    "Feature importance for a particular email is directly proportional to Term frequency in that email and indirectly proportional to document frequency (i.e number of documents that are having the words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(tfidf_score, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796602057908591"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(tfidf_score, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the text data also to get the tfidf score so that we can make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>These won't do. Have to move on to morphine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>Hmm...Bad news...Hype park plaza $700 studio t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>when you and derek done with class?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>Hey happy birthday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>I.ll hand her my phone to chat wit u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "4635        These won't do. Have to move on to morphine\n",
       "2279  Hmm...Bad news...Hype park plaza $700 studio t...\n",
       "4545                when you and derek done with class?\n",
       "5084                              Hey happy birthday...\n",
       "5298               I.ll hand her my phone to chat wit u"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bows = bow.transform(X_test.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7257 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf=tfidf.transform(X_test_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7257 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = nb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569274946159368"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
