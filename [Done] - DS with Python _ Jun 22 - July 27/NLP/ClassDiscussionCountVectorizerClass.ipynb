{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"The Indian subcontinent was home to the Indus Valley Civilisation of the bronze age. In India's iron age, the oldest scriptures of Hinduism were composed, social stratification based on caste emerged, and Buddhism and Jainism arose. Political consolidations took place under the Maurya and Gupta Empires; the peninsular Middle Kingdoms influenced the cultures of Southeast Asia. In India's medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived, and Sikhism emerged, adding to a diverse culture. North India fell to the Delhi Sultanate; south India was united under the Vijayanagara Empire. In the early modern era, the expansive Mughal Empire was followed by East India Company rule.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Indian subcontinent was home to the Indus Valley Civilisation of the bronze age.',\n",
       " \"In India's iron age, the oldest scriptures of Hinduism were composed, social stratification based on caste emerged, and Buddhism and Jainism arose.\",\n",
       " 'Political consolidations took place under the Maurya and Gupta Empires; the peninsular Middle Kingdoms influenced the cultures of Southeast Asia.',\n",
       " \"In India's medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived, and Sikhism emerged, adding to a diverse culture.\",\n",
       " 'North India fell to the Delhi Sultanate; south India was united under the Vijayanagara Empire.',\n",
       " 'In the early modern era, the expansive Mughal Empire was followed by East India Company rule.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]=texts[0]+\".****....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[1] = texts[1]+\"1345**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts.append(\"372-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Indian subcontinent was home to the Indus Valley Civilisation of the bronze age..****....',\n",
       " \"In India's iron age, the oldest scriptures of Hinduism were composed, social stratification based on caste emerged, and Buddhism and Jainism arose.1345**\",\n",
       " 'Political consolidations took place under the Maurya and Gupta Empires; the peninsular Middle Kingdoms influenced the cultures of Southeast Asia.',\n",
       " \"In India's medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived, and Sikhism emerged, adding to a diverse culture.\",\n",
       " 'North India fell to the Delhi Sultanate; south India was united under the Vijayanagara Empire.',\n",
       " 'In the early modern era, the expansive Mughal Empire was followed by East India Company rule.',\n",
       " '372-12']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#vect_cv = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect_cv = TfidfVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '1345', '372', 'adding', 'age', 'and', 'arose', 'arrived', 'asia', 'based', 'bronze', 'buddhism', 'by', 'caste', 'christianity', 'civilisation', 'company', 'composed', 'consolidations', 'culture', 'cultures', 'delhi', 'diverse', 'early', 'east', 'emerged', 'empire', 'empires', 'era', 'expansive', 'fell', 'followed', 'gupta', 'hinduism', 'home', 'in', 'india', 'indian', 'indus', 'influenced', 'iron', 'islam', 'jainism', 'judaism', 'kingdoms', 'maurya', 'medieval', 'middle', 'modern', 'mughal', 'north', 'of', 'oldest', 'on', 'peninsular', 'place', 'political', 'rule', 'scriptures', 'sikhism', 'social', 'south', 'southeast', 'stratification', 'subcontinent', 'sultanate', 'the', 'to', 'took', 'under', 'united', 'valley', 'vijayanagara', 'was', 'were', 'zoroastrianism']\n"
     ]
    }
   ],
   "source": [
    "print(vect_cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 66, 'indian': 37, 'subcontinent': 64, 'was': 73, 'home': 34, 'to': 67, 'indus': 38, 'valley': 71, 'civilisation': 15, 'of': 51, 'bronze': 10, 'age': 4, 'in': 35, 'india': 36, 'iron': 40, 'oldest': 52, 'scriptures': 58, 'hinduism': 33, 'were': 74, 'composed': 17, 'social': 60, 'stratification': 63, 'based': 9, 'on': 53, 'caste': 13, 'emerged': 25, 'and': 5, 'buddhism': 11, 'jainism': 42, 'arose': 6, '1345': 1, 'political': 56, 'consolidations': 18, 'took': 68, 'place': 55, 'under': 69, 'maurya': 45, 'gupta': 32, 'empires': 27, 'peninsular': 54, 'middle': 47, 'kingdoms': 44, 'influenced': 39, 'cultures': 20, 'southeast': 62, 'asia': 8, 'medieval': 46, 'era': 28, 'judaism': 43, 'zoroastrianism': 75, 'christianity': 14, 'islam': 41, 'arrived': 7, 'sikhism': 59, 'adding': 3, 'diverse': 22, 'culture': 19, 'north': 50, 'fell': 30, 'delhi': 21, 'sultanate': 65, 'south': 61, 'united': 70, 'vijayanagara': 72, 'empire': 26, 'early': 23, 'modern': 48, 'expansive': 29, 'mughal': 49, 'followed': 31, 'by': 12, 'east': 24, 'company': 16, 'rule': 57, '372': 2, '12': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vect_cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x76 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 98 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = vect_cv.transform(texts)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 76)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.24144274,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29086478, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29086478, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29086478,\n",
       "        0.        , 0.        , 0.29086478, 0.29086478, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20637725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29086478,\n",
       "        0.        , 0.47086566, 0.20637725, 0.        , 0.        ,\n",
       "        0.        , 0.29086478, 0.        , 0.20637725, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.22322015, 0.        , 0.        , 0.18529189,\n",
       "        0.31676273, 0.22322015, 0.        , 0.        , 0.22322015,\n",
       "        0.        , 0.22322015, 0.        , 0.22322015, 0.        ,\n",
       "        0.        , 0.        , 0.22322015, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18529189, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.22322015, 0.        ,\n",
       "        0.15838137, 0.13750794, 0.        , 0.        , 0.        ,\n",
       "        0.22322015, 0.        , 0.22322015, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15838137, 0.22322015, 0.22322015, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.22322015, 0.        ,\n",
       "        0.22322015, 0.        , 0.        , 0.22322015, 0.        ,\n",
       "        0.        , 0.12045311, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.22322015,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16578627, 0.        , 0.        , 0.2336565 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2336565 , 0.        ,\n",
       "        0.2336565 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2336565 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2336565 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2336565 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2336565 ,\n",
       "        0.2336565 , 0.        , 0.2336565 , 0.        , 0.        ,\n",
       "        0.        , 0.16578627, 0.        , 0.        , 0.2336565 ,\n",
       "        0.2336565 , 0.2336565 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2336565 , 0.        , 0.        ,\n",
       "        0.        , 0.3782542 , 0.        , 0.2336565 , 0.19395496,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.26012962, 0.        ,\n",
       "        0.36913948, 0.        , 0.26012962, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26012962,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26012962,\n",
       "        0.        , 0.        , 0.26012962, 0.        , 0.        ,\n",
       "        0.21592992, 0.        , 0.        , 0.21592992, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18456974, 0.16024489, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26012962, 0.        , 0.26012962, 0.        ,\n",
       "        0.        , 0.26012962, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.26012962,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18456974, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.26012962],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28786532, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23895294, 0.        , 0.        , 0.        ,\n",
       "        0.28786532, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.35466125, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28786532, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28786532, 0.        , 0.        , 0.        ,\n",
       "        0.28786532, 0.31067334, 0.20424905, 0.        , 0.23895294,\n",
       "        0.28786532, 0.        , 0.28786532, 0.20424905, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27810875, 0.        , 0.        ,\n",
       "        0.        , 0.27810875, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27810875, 0.27810875,\n",
       "        0.        , 0.23085415, 0.        , 0.23085415, 0.27810875,\n",
       "        0.        , 0.27810875, 0.        , 0.        , 0.        ,\n",
       "        0.19732647, 0.17132039, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27810875, 0.27810875,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27810875, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30014374, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19732647, 0.        ,\n",
       "        0.        ],\n",
       "       [0.70710678, 0.        , 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.toarray() #to get the dense matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>1345</th>\n",
       "      <th>372</th>\n",
       "      <th>adding</th>\n",
       "      <th>age</th>\n",
       "      <th>and</th>\n",
       "      <th>arose</th>\n",
       "      <th>arrived</th>\n",
       "      <th>asia</th>\n",
       "      <th>based</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>took</th>\n",
       "      <th>under</th>\n",
       "      <th>united</th>\n",
       "      <th>valley</th>\n",
       "      <th>vijayanagara</th>\n",
       "      <th>was</th>\n",
       "      <th>were</th>\n",
       "      <th>zoroastrianism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.241443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470866</td>\n",
       "      <td>0.206377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206377</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.22322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.185292</td>\n",
       "      <td>0.316763</td>\n",
       "      <td>0.22322</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.22322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.22322</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233657</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233657</td>\n",
       "      <td>0.193955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369139</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.26013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.26013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310673</td>\n",
       "      <td>0.204249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238953</td>\n",
       "      <td>0.287865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287865</td>\n",
       "      <td>0.204249</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197326</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         12     1345       372   adding       age       and    arose  arrived  \\\n",
       "0  0.000000  0.00000  0.000000  0.00000  0.241443  0.000000  0.00000  0.00000   \n",
       "1  0.000000  0.22322  0.000000  0.00000  0.185292  0.316763  0.22322  0.00000   \n",
       "2  0.000000  0.00000  0.000000  0.00000  0.000000  0.165786  0.00000  0.00000   \n",
       "3  0.000000  0.00000  0.000000  0.26013  0.000000  0.369139  0.00000  0.26013   \n",
       "4  0.000000  0.00000  0.000000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "5  0.000000  0.00000  0.000000  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "6  0.707107  0.00000  0.707107  0.00000  0.000000  0.000000  0.00000  0.00000   \n",
       "\n",
       "       asia    based  ...       the        to      took     under    united  \\\n",
       "0  0.000000  0.00000  ...  0.470866  0.206377  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.22322  ...  0.120453  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.233657  0.00000  ...  0.378254  0.000000  0.233657  0.193955  0.000000   \n",
       "3  0.000000  0.00000  ...  0.000000  0.184570  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.00000  ...  0.310673  0.204249  0.000000  0.238953  0.287865   \n",
       "5  0.000000  0.00000  ...  0.300144  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.00000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     valley  vijayanagara       was     were  zoroastrianism  \n",
       "0  0.290865      0.000000  0.206377  0.00000         0.00000  \n",
       "1  0.000000      0.000000  0.000000  0.22322         0.00000  \n",
       "2  0.000000      0.000000  0.000000  0.00000         0.00000  \n",
       "3  0.000000      0.000000  0.000000  0.00000         0.26013  \n",
       "4  0.000000      0.287865  0.204249  0.00000         0.00000  \n",
       "5  0.000000      0.000000  0.197326  0.00000         0.00000  \n",
       "6  0.000000      0.000000  0.000000  0.00000         0.00000  \n",
       "\n",
       "[7 rows x 76 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tr.toarray(), columns = vect_cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you put binary = True then we can get the presence of absence of the word instead of the count\n",
    "vect_cv = CountVectorizer(binary = True)\n",
    "vect_cv.fit(texts)\n",
    "bow = vect_cv.transform(texts)\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ngram = (1,2) or bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-grams (sets of consecutive words) N=2\n",
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train (Bow) \n",
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 173\n",
      "['12', '1345', '372', '372 12', 'adding', 'adding to', 'age', 'age the', 'and', 'and buddhism', 'and gupta', 'and islam', 'and jainism', 'and sikhism', 'arose', 'arose 1345', 'arrived', 'arrived and', 'asia', 'based', 'based on', 'bronze', 'bronze age', 'buddhism', 'buddhism and', 'by', 'by east', 'caste', 'caste emerged', 'christianity', 'christianity and', 'civilisation', 'civilisation of', 'company', 'company rule', 'composed', 'composed social', 'consolidations', 'consolidations took', 'culture', 'cultures', 'cultures of', 'delhi', 'delhi sultanate', 'diverse', 'diverse culture', 'early', 'early modern', 'east', 'east india', 'emerged', 'emerged adding', 'emerged and', 'empire', 'empire was', 'empires', 'empires the', 'era', 'era judaism', 'era the', 'expansive', 'expansive mughal', 'fell', 'fell to', 'followed', 'followed by', 'gupta', 'gupta empires', 'hinduism', 'hinduism were', 'home', 'home to', 'in', 'in india', 'in the', 'india', 'india company', 'india fell', 'india iron', 'india medieval', 'india was', 'indian', 'indian subcontinent', 'indus', 'indus valley', 'influenced', 'influenced the', 'iron', 'iron age', 'islam', 'islam arrived', 'jainism', 'jainism arose', 'judaism', 'judaism zoroastrianism', 'kingdoms', 'kingdoms influenced', 'maurya', 'maurya and', 'medieval', 'medieval era', 'middle', 'middle kingdoms', 'modern', 'modern era', 'mughal', 'mughal empire', 'north', 'north india', 'of', 'of hinduism', 'of southeast', 'of the', 'oldest', 'oldest scriptures', 'on', 'on caste', 'peninsular', 'peninsular middle', 'place', 'place under', 'political', 'political consolidations', 'rule', 'scriptures', 'scriptures of', 'sikhism', 'sikhism emerged', 'social', 'social stratification', 'south', 'south india', 'southeast', 'southeast asia', 'stratification', 'stratification based', 'subcontinent', 'subcontinent was', 'sultanate', 'sultanate south', 'the', 'the bronze', 'the cultures', 'the delhi', 'the early', 'the expansive', 'the indian', 'the indus', 'the maurya', 'the oldest', 'the peninsular', 'the vijayanagara', 'to', 'to diverse', 'to the', 'took', 'took place', 'under', 'under the', 'united', 'united under', 'valley', 'valley civilisation', 'vijayanagara', 'vijayanagara empire', 'was', 'was followed', 'was home', 'was united', 'were', 'were composed', 'zoroastrianism', 'zoroastrianism christianity']\n",
      "\n",
      "\n",
      "Vocabulary content:\n",
      " {'the': 140, 'indian': 81, 'subcontinent': 136, 'was': 165, 'home': 70, 'to': 152, 'indus': 83, 'valley': 161, 'civilisation': 31, 'of': 109, 'bronze': 21, 'age': 6, 'the indian': 146, 'indian subcontinent': 82, 'subcontinent was': 137, 'was home': 167, 'home to': 71, 'to the': 154, 'the indus': 147, 'indus valley': 84, 'valley civilisation': 162, 'civilisation of': 32, 'of the': 112, 'the bronze': 141, 'bronze age': 22, 'in': 72, 'india': 75, 'iron': 87, 'oldest': 113, 'scriptures': 124, 'hinduism': 68, 'were': 169, 'composed': 35, 'social': 128, 'stratification': 134, 'based': 19, 'on': 115, 'caste': 27, 'emerged': 50, 'and': 8, 'buddhism': 23, 'jainism': 91, 'arose': 14, '1345': 1, 'in india': 73, 'india iron': 78, 'iron age': 88, 'age the': 7, 'the oldest': 149, 'oldest scriptures': 114, 'scriptures of': 125, 'of hinduism': 110, 'hinduism were': 69, 'were composed': 170, 'composed social': 36, 'social stratification': 129, 'stratification based': 135, 'based on': 20, 'on caste': 116, 'caste emerged': 28, 'emerged and': 52, 'and buddhism': 9, 'buddhism and': 24, 'and jainism': 12, 'jainism arose': 92, 'arose 1345': 15, 'political': 121, 'consolidations': 37, 'took': 155, 'place': 119, 'under': 157, 'maurya': 97, 'gupta': 66, 'empires': 55, 'peninsular': 117, 'middle': 101, 'kingdoms': 95, 'influenced': 85, 'cultures': 40, 'southeast': 132, 'asia': 18, 'political consolidations': 122, 'consolidations took': 38, 'took place': 156, 'place under': 120, 'under the': 158, 'the maurya': 148, 'maurya and': 98, 'and gupta': 10, 'gupta empires': 67, 'empires the': 56, 'the peninsular': 150, 'peninsular middle': 118, 'middle kingdoms': 102, 'kingdoms influenced': 96, 'influenced the': 86, 'the cultures': 142, 'cultures of': 41, 'of southeast': 111, 'southeast asia': 133, 'medieval': 99, 'era': 57, 'judaism': 93, 'zoroastrianism': 171, 'christianity': 29, 'islam': 89, 'arrived': 16, 'sikhism': 126, 'adding': 4, 'diverse': 44, 'culture': 39, 'india medieval': 79, 'medieval era': 100, 'era judaism': 58, 'judaism zoroastrianism': 94, 'zoroastrianism christianity': 172, 'christianity and': 30, 'and islam': 11, 'islam arrived': 90, 'arrived and': 17, 'and sikhism': 13, 'sikhism emerged': 127, 'emerged adding': 51, 'adding to': 5, 'to diverse': 153, 'diverse culture': 45, 'north': 107, 'fell': 62, 'delhi': 42, 'sultanate': 138, 'south': 130, 'united': 159, 'vijayanagara': 163, 'empire': 53, 'north india': 108, 'india fell': 77, 'fell to': 63, 'the delhi': 143, 'delhi sultanate': 43, 'sultanate south': 139, 'south india': 131, 'india was': 80, 'was united': 168, 'united under': 160, 'the vijayanagara': 151, 'vijayanagara empire': 164, 'early': 46, 'modern': 103, 'expansive': 60, 'mughal': 105, 'followed': 64, 'by': 25, 'east': 48, 'company': 33, 'rule': 123, 'in the': 74, 'the early': 144, 'early modern': 47, 'modern era': 104, 'era the': 59, 'the expansive': 145, 'expansive mughal': 61, 'mughal empire': 106, 'empire was': 54, 'was followed': 166, 'followed by': 65, 'by east': 26, 'east india': 49, 'india company': 76, 'company rule': 34, '372': 2, '12': 0, '372 12': 3}\n"
     ]
    }
   ],
   "source": [
    "# get all the feature/token names\n",
    "print(\"Vocabulary size: {}\".format(len(vect_cv.vocabulary_)))\n",
    "\n",
    "feature_names = vect_cv.get_feature_names()\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\n\\nVocabulary content:\\n {}\".format(vect_cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dtm\n",
    "X_train_cv_dtm = vect_cv.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>1345</th>\n",
       "      <th>372</th>\n",
       "      <th>372 12</th>\n",
       "      <th>adding</th>\n",
       "      <th>adding to</th>\n",
       "      <th>age</th>\n",
       "      <th>age the</th>\n",
       "      <th>and</th>\n",
       "      <th>and buddhism</th>\n",
       "      <th>...</th>\n",
       "      <th>vijayanagara</th>\n",
       "      <th>vijayanagara empire</th>\n",
       "      <th>was</th>\n",
       "      <th>was followed</th>\n",
       "      <th>was home</th>\n",
       "      <th>was united</th>\n",
       "      <th>were</th>\n",
       "      <th>were composed</th>\n",
       "      <th>zoroastrianism</th>\n",
       "      <th>zoroastrianism christianity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   12  1345  372  372 12  adding  adding to  age  age the  and  and buddhism  \\\n",
       "0   0     0    0       0       0          0    1        0    0             0   \n",
       "1   0     1    0       0       0          0    1        1    2             1   \n",
       "2   0     0    0       0       0          0    0        0    1             0   \n",
       "3   0     0    0       0       1          1    0        0    2             0   \n",
       "4   0     0    0       0       0          0    0        0    0             0   \n",
       "5   0     0    0       0       0          0    0        0    0             0   \n",
       "6   1     0    1       1       0          0    0        0    0             0   \n",
       "\n",
       "   ...  vijayanagara  vijayanagara empire  was  was followed  was home  \\\n",
       "0  ...             0                    0    1             0         1   \n",
       "1  ...             0                    0    0             0         0   \n",
       "2  ...             0                    0    0             0         0   \n",
       "3  ...             0                    0    0             0         0   \n",
       "4  ...             1                    1    1             0         0   \n",
       "5  ...             0                    0    1             1         0   \n",
       "6  ...             0                    0    0             0         0   \n",
       "\n",
       "   was united  were  were composed  zoroastrianism  \\\n",
       "0           0     0              0               0   \n",
       "1           0     1              1               0   \n",
       "2           0     0              0               0   \n",
       "3           0     0              0               1   \n",
       "4           1     0              0               0   \n",
       "5           0     0              0               0   \n",
       "6           0     0              0               0   \n",
       "\n",
       "   zoroastrianism christianity  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  \n",
       "5                            0  \n",
       "6                            0  \n",
       "\n",
       "[7 rows x 173 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "pd.DataFrame(X_train_cv_dtm.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ngrams (1,3)\n",
    "eg. East India Company\n",
    "Indus Valley Civilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N=3\n",
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train (Bow) \n",
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 266\n",
      "['12', '1345', '372', '372 12', 'adding', 'adding to', 'adding to diverse', 'age', 'age the', 'age the oldest', 'and', 'and buddhism', 'and buddhism and', 'and gupta', 'and gupta empires', 'and islam', 'and islam arrived', 'and jainism', 'and jainism arose', 'and sikhism', 'and sikhism emerged', 'arose', 'arose 1345', 'arrived', 'arrived and', 'arrived and sikhism', 'asia', 'based', 'based on', 'based on caste', 'bronze', 'bronze age', 'buddhism', 'buddhism and', 'buddhism and jainism', 'by', 'by east', 'by east india', 'caste', 'caste emerged', 'caste emerged and', 'christianity', 'christianity and', 'christianity and islam', 'civilisation', 'civilisation of', 'civilisation of the', 'company', 'company rule', 'composed', 'composed social', 'composed social stratification', 'consolidations', 'consolidations took', 'consolidations took place', 'culture', 'cultures', 'cultures of', 'cultures of southeast', 'delhi', 'delhi sultanate', 'delhi sultanate south', 'diverse', 'diverse culture', 'early', 'early modern', 'early modern era', 'east', 'east india', 'east india company', 'emerged', 'emerged adding', 'emerged adding to', 'emerged and', 'emerged and buddhism', 'empire', 'empire was', 'empire was followed', 'empires', 'empires the', 'empires the peninsular', 'era', 'era judaism', 'era judaism zoroastrianism', 'era the', 'era the expansive', 'expansive', 'expansive mughal', 'expansive mughal empire', 'fell', 'fell to', 'fell to the', 'followed', 'followed by', 'followed by east', 'gupta', 'gupta empires', 'gupta empires the', 'hinduism', 'hinduism were', 'hinduism were composed', 'home', 'home to', 'home to the', 'in', 'in india', 'in india iron', 'in india medieval', 'in the', 'in the early', 'india', 'india company', 'india company rule', 'india fell', 'india fell to', 'india iron', 'india iron age', 'india medieval', 'india medieval era', 'india was', 'india was united', 'indian', 'indian subcontinent', 'indian subcontinent was', 'indus', 'indus valley', 'indus valley civilisation', 'influenced', 'influenced the', 'influenced the cultures', 'iron', 'iron age', 'iron age the', 'islam', 'islam arrived', 'islam arrived and', 'jainism', 'jainism arose', 'jainism arose 1345', 'judaism', 'judaism zoroastrianism', 'judaism zoroastrianism christianity', 'kingdoms', 'kingdoms influenced', 'kingdoms influenced the', 'maurya', 'maurya and', 'maurya and gupta', 'medieval', 'medieval era', 'medieval era judaism', 'middle', 'middle kingdoms', 'middle kingdoms influenced', 'modern', 'modern era', 'modern era the', 'mughal', 'mughal empire', 'mughal empire was', 'north', 'north india', 'north india fell', 'of', 'of hinduism', 'of hinduism were', 'of southeast', 'of southeast asia', 'of the', 'of the bronze', 'oldest', 'oldest scriptures', 'oldest scriptures of', 'on', 'on caste', 'on caste emerged', 'peninsular', 'peninsular middle', 'peninsular middle kingdoms', 'place', 'place under', 'place under the', 'political', 'political consolidations', 'political consolidations took', 'rule', 'scriptures', 'scriptures of', 'scriptures of hinduism', 'sikhism', 'sikhism emerged', 'sikhism emerged adding', 'social', 'social stratification', 'social stratification based', 'south', 'south india', 'south india was', 'southeast', 'southeast asia', 'stratification', 'stratification based', 'stratification based on', 'subcontinent', 'subcontinent was', 'subcontinent was home', 'sultanate', 'sultanate south', 'sultanate south india', 'the', 'the bronze', 'the bronze age', 'the cultures', 'the cultures of', 'the delhi', 'the delhi sultanate', 'the early', 'the early modern', 'the expansive', 'the expansive mughal', 'the indian', 'the indian subcontinent', 'the indus', 'the indus valley', 'the maurya', 'the maurya and', 'the oldest', 'the oldest scriptures', 'the peninsular', 'the peninsular middle', 'the vijayanagara', 'the vijayanagara empire', 'to', 'to diverse', 'to diverse culture', 'to the', 'to the delhi', 'to the indus', 'took', 'took place', 'took place under', 'under', 'under the', 'under the maurya', 'under the vijayanagara', 'united', 'united under', 'united under the', 'valley', 'valley civilisation', 'valley civilisation of', 'vijayanagara', 'vijayanagara empire', 'was', 'was followed', 'was followed by', 'was home', 'was home to', 'was united', 'was united under', 'were', 'were composed', 'were composed social', 'zoroastrianism', 'zoroastrianism christianity', 'zoroastrianism christianity and']\n",
      "Vocabulary content:\n",
      " {'the': 209, 'indian': 121, 'subcontinent': 203, 'was': 253, 'home': 101, 'to': 232, 'indus': 124, 'valley': 248, 'civilisation': 44, 'of': 163, 'bronze': 30, 'age': 7, 'the indian': 220, 'indian subcontinent': 122, 'subcontinent was': 204, 'was home': 256, 'home to': 102, 'to the': 235, 'the indus': 222, 'indus valley': 125, 'valley civilisation': 249, 'civilisation of': 45, 'of the': 168, 'the bronze': 210, 'bronze age': 31, 'the indian subcontinent': 221, 'indian subcontinent was': 123, 'subcontinent was home': 205, 'was home to': 257, 'home to the': 103, 'to the indus': 237, 'the indus valley': 223, 'indus valley civilisation': 126, 'valley civilisation of': 250, 'civilisation of the': 46, 'of the bronze': 169, 'the bronze age': 211, 'in': 104, 'india': 110, 'iron': 130, 'oldest': 170, 'scriptures': 186, 'hinduism': 98, 'were': 260, 'composed': 49, 'social': 192, 'stratification': 200, 'based': 27, 'on': 173, 'caste': 38, 'emerged': 70, 'and': 10, 'buddhism': 32, 'jainism': 136, 'arose': 21, '1345': 1, 'in india': 105, 'india iron': 115, 'iron age': 131, 'age the': 8, 'the oldest': 226, 'oldest scriptures': 171, 'scriptures of': 187, 'of hinduism': 164, 'hinduism were': 99, 'were composed': 261, 'composed social': 50, 'social stratification': 193, 'stratification based': 201, 'based on': 28, 'on caste': 174, 'caste emerged': 39, 'emerged and': 73, 'and buddhism': 11, 'buddhism and': 33, 'and jainism': 17, 'jainism arose': 137, 'arose 1345': 22, 'in india iron': 106, 'india iron age': 116, 'iron age the': 132, 'age the oldest': 9, 'the oldest scriptures': 227, 'oldest scriptures of': 172, 'scriptures of hinduism': 188, 'of hinduism were': 165, 'hinduism were composed': 100, 'were composed social': 262, 'composed social stratification': 51, 'social stratification based': 194, 'stratification based on': 202, 'based on caste': 29, 'on caste emerged': 175, 'caste emerged and': 40, 'emerged and buddhism': 74, 'and buddhism and': 12, 'buddhism and jainism': 34, 'and jainism arose': 18, 'jainism arose 1345': 138, 'political': 182, 'consolidations': 52, 'took': 238, 'place': 179, 'under': 241, 'maurya': 145, 'gupta': 95, 'empires': 78, 'peninsular': 176, 'middle': 151, 'kingdoms': 142, 'influenced': 127, 'cultures': 56, 'southeast': 198, 'asia': 26, 'political consolidations': 183, 'consolidations took': 53, 'took place': 239, 'place under': 180, 'under the': 242, 'the maurya': 224, 'maurya and': 146, 'and gupta': 13, 'gupta empires': 96, 'empires the': 79, 'the peninsular': 228, 'peninsular middle': 177, 'middle kingdoms': 152, 'kingdoms influenced': 143, 'influenced the': 128, 'the cultures': 212, 'cultures of': 57, 'of southeast': 166, 'southeast asia': 199, 'political consolidations took': 184, 'consolidations took place': 54, 'took place under': 240, 'place under the': 181, 'under the maurya': 243, 'the maurya and': 225, 'maurya and gupta': 147, 'and gupta empires': 14, 'gupta empires the': 97, 'empires the peninsular': 80, 'the peninsular middle': 229, 'peninsular middle kingdoms': 178, 'middle kingdoms influenced': 153, 'kingdoms influenced the': 144, 'influenced the cultures': 129, 'the cultures of': 213, 'cultures of southeast': 58, 'of southeast asia': 167, 'medieval': 148, 'era': 81, 'judaism': 139, 'zoroastrianism': 263, 'christianity': 41, 'islam': 133, 'arrived': 23, 'sikhism': 189, 'adding': 4, 'diverse': 62, 'culture': 55, 'india medieval': 117, 'medieval era': 149, 'era judaism': 82, 'judaism zoroastrianism': 140, 'zoroastrianism christianity': 264, 'christianity and': 42, 'and islam': 15, 'islam arrived': 134, 'arrived and': 24, 'and sikhism': 19, 'sikhism emerged': 190, 'emerged adding': 71, 'adding to': 5, 'to diverse': 233, 'diverse culture': 63, 'in india medieval': 107, 'india medieval era': 118, 'medieval era judaism': 150, 'era judaism zoroastrianism': 83, 'judaism zoroastrianism christianity': 141, 'zoroastrianism christianity and': 265, 'christianity and islam': 43, 'and islam arrived': 16, 'islam arrived and': 135, 'arrived and sikhism': 25, 'and sikhism emerged': 20, 'sikhism emerged adding': 191, 'emerged adding to': 72, 'adding to diverse': 6, 'to diverse culture': 234, 'north': 160, 'fell': 89, 'delhi': 59, 'sultanate': 206, 'south': 195, 'united': 245, 'vijayanagara': 251, 'empire': 75, 'north india': 161, 'india fell': 113, 'fell to': 90, 'the delhi': 214, 'delhi sultanate': 60, 'sultanate south': 207, 'south india': 196, 'india was': 119, 'was united': 258, 'united under': 246, 'the vijayanagara': 230, 'vijayanagara empire': 252, 'north india fell': 162, 'india fell to': 114, 'fell to the': 91, 'to the delhi': 236, 'the delhi sultanate': 215, 'delhi sultanate south': 61, 'sultanate south india': 208, 'south india was': 197, 'india was united': 120, 'was united under': 259, 'united under the': 247, 'under the vijayanagara': 244, 'the vijayanagara empire': 231, 'early': 64, 'modern': 154, 'expansive': 86, 'mughal': 157, 'followed': 92, 'by': 35, 'east': 67, 'company': 47, 'rule': 185, 'in the': 108, 'the early': 216, 'early modern': 65, 'modern era': 155, 'era the': 84, 'the expansive': 218, 'expansive mughal': 87, 'mughal empire': 158, 'empire was': 76, 'was followed': 254, 'followed by': 93, 'by east': 36, 'east india': 68, 'india company': 111, 'company rule': 48, 'in the early': 109, 'the early modern': 217, 'early modern era': 66, 'modern era the': 156, 'era the expansive': 85, 'the expansive mughal': 219, 'expansive mughal empire': 88, 'mughal empire was': 159, 'empire was followed': 77, 'was followed by': 255, 'followed by east': 94, 'by east india': 37, 'east india company': 69, 'india company rule': 112, '372': 2, '12': 0, '372 12': 3}\n"
     ]
    }
   ],
   "source": [
    "# get all the feature/token names\n",
    "print(\"Vocabulary size: {}\".format(len(vect_cv.vocabulary_)))\n",
    "\n",
    "feature_names = vect_cv.get_feature_names()\n",
    "print(feature_names)\n",
    "\n",
    "print(\"Vocabulary content:\\n {}\".format(vect_cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dtm\n",
    "X_train_cv_dtm = vect_cv.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>1345</th>\n",
       "      <th>372</th>\n",
       "      <th>372 12</th>\n",
       "      <th>adding</th>\n",
       "      <th>adding to</th>\n",
       "      <th>adding to diverse</th>\n",
       "      <th>age</th>\n",
       "      <th>age the</th>\n",
       "      <th>age the oldest</th>\n",
       "      <th>...</th>\n",
       "      <th>was home</th>\n",
       "      <th>was home to</th>\n",
       "      <th>was united</th>\n",
       "      <th>was united under</th>\n",
       "      <th>were</th>\n",
       "      <th>were composed</th>\n",
       "      <th>were composed social</th>\n",
       "      <th>zoroastrianism</th>\n",
       "      <th>zoroastrianism christianity</th>\n",
       "      <th>zoroastrianism christianity and</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   12  1345  372  372 12  adding  adding to  adding to diverse  age  age the  \\\n",
       "0   0     0    0       0       0          0                  0    1        0   \n",
       "1   0     1    0       0       0          0                  0    1        1   \n",
       "2   0     0    0       0       0          0                  0    0        0   \n",
       "3   0     0    0       0       1          1                  1    0        0   \n",
       "4   0     0    0       0       0          0                  0    0        0   \n",
       "5   0     0    0       0       0          0                  0    0        0   \n",
       "6   1     0    1       1       0          0                  0    0        0   \n",
       "\n",
       "   age the oldest  ...  was home  was home to  was united  was united under  \\\n",
       "0               0  ...         1            1           0                 0   \n",
       "1               1  ...         0            0           0                 0   \n",
       "2               0  ...         0            0           0                 0   \n",
       "3               0  ...         0            0           0                 0   \n",
       "4               0  ...         0            0           1                 1   \n",
       "5               0  ...         0            0           0                 0   \n",
       "6               0  ...         0            0           0                 0   \n",
       "\n",
       "   were  were composed  were composed social  zoroastrianism  \\\n",
       "0     0              0                     0               0   \n",
       "1     1              1                     1               0   \n",
       "2     0              0                     0               0   \n",
       "3     0              0                     0               1   \n",
       "4     0              0                     0               0   \n",
       "5     0              0                     0               0   \n",
       "6     0              0                     0               0   \n",
       "\n",
       "   zoroastrianism christianity  zoroastrianism christianity and  \n",
       "0                            0                                0  \n",
       "1                            0                                0  \n",
       "2                            0                                0  \n",
       "3                            1                                1  \n",
       "4                            0                                0  \n",
       "5                            0                                0  \n",
       "6                            0                                0  \n",
       "\n",
       "[7 rows x 266 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "pd.DataFrame(X_train_cv_dtm.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min_df\n",
    "\n",
    "# Min_df ignores terms that have a document frequency (presence in % of documents) strictly lower \n",
    "# than the given threshold. \n",
    "# For example, Min_df=0.66 requires that a term appear in 66% of the docuemnts for it to be considered \n",
    "# part of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes min_df is used to limit the vocabulary size, so it learns only those terms that appear \n",
    "# in at least 10%, 20%, etc. of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=0.2, max_features=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max_df: When building the vocabulary, it ignores terms that have a document \n",
    "# frequency strictly higher than the given threshold. \n",
    "\n",
    "# This could be used to exclude terms that are too frequent and are \n",
    "# unlikely to help predict the label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 1), max_df=0.5, min_df=0.2, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max_features\n",
    "\n",
    "# Limit the amount of features (vocabulary) that the vectorizer will learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 1), max_df=0.5, min_df=0.2, max_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.5, max_features=6, min_df=0.2,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train (Bow) \n",
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6\n",
      "['age', 'and', 'in', 'of', 'to', 'was']\n",
      "Vocabulary content:\n",
      " {'was': 5, 'to': 4, 'of': 3, 'age': 0, 'in': 2, 'and': 1}\n"
     ]
    }
   ],
   "source": [
    "# get all the feature/token names\n",
    "print(\"Vocabulary size: {}\".format(len(vect_cv.vocabulary_)))\n",
    "\n",
    "feature_names = vect_cv.get_feature_names()\n",
    "print(feature_names)\n",
    "\n",
    "print(\"Vocabulary content:\\n {}\".format(vect_cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "\n",
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 1), stop_words='english', max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train (Bow) \n",
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 66\n",
      "['12', '1345', '372', 'adding', 'age', 'arose', 'arrived', 'asia', 'based', 'bronze', 'buddhism', 'caste', 'christianity', 'civilisation', 'company', 'composed', 'consolidations', 'culture', 'cultures', 'delhi', 'diverse', 'early', 'east', 'emerged', 'empire', 'empires', 'era', 'expansive', 'fell', 'followed', 'gupta', 'hinduism', 'home', 'india', 'indian', 'indus', 'influenced', 'iron', 'islam', 'jainism', 'judaism', 'kingdoms', 'maurya', 'medieval', 'middle', 'modern', 'mughal', 'north', 'oldest', 'peninsular', 'place', 'political', 'rule', 'scriptures', 'sikhism', 'social', 'south', 'southeast', 'stratification', 'subcontinent', 'sultanate', 'took', 'united', 'valley', 'vijayanagara', 'zoroastrianism']\n",
      "Vocabulary content:\n",
      " {'indian': 34, 'subcontinent': 59, 'home': 32, 'indus': 35, 'valley': 63, 'civilisation': 13, 'bronze': 9, 'age': 4, 'india': 33, 'iron': 37, 'oldest': 48, 'scriptures': 53, 'hinduism': 31, 'composed': 15, 'social': 55, 'stratification': 58, 'based': 8, 'caste': 11, 'emerged': 23, 'buddhism': 10, 'jainism': 39, 'arose': 5, '1345': 1, 'political': 51, 'consolidations': 16, 'took': 61, 'place': 50, 'maurya': 42, 'gupta': 30, 'empires': 25, 'peninsular': 49, 'middle': 44, 'kingdoms': 41, 'influenced': 36, 'cultures': 18, 'southeast': 57, 'asia': 7, 'medieval': 43, 'era': 26, 'judaism': 40, 'zoroastrianism': 65, 'christianity': 12, 'islam': 38, 'arrived': 6, 'sikhism': 54, 'adding': 3, 'diverse': 20, 'culture': 17, 'north': 47, 'fell': 28, 'delhi': 19, 'sultanate': 60, 'south': 56, 'united': 62, 'vijayanagara': 64, 'empire': 24, 'early': 21, 'modern': 45, 'expansive': 27, 'mughal': 46, 'followed': 29, 'east': 22, 'company': 14, 'rule': 52, '372': 2, '12': 0}\n"
     ]
    }
   ],
   "source": [
    "# get all the feature/token names\n",
    "print(\"Vocabulary size: {}\".format(len(vect_cv.vocabulary_)))\n",
    "\n",
    "feature_names = vect_cv.get_feature_names()\n",
    "print(feature_names)\n",
    "\n",
    "print(\"Vocabulary content:\\n {}\".format(vect_cv.vocabulary_))\n",
    "#notice all the stopwords like the / and have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countvectorizer class can't do stemming\n",
    "For this we need to modify the tokenizer parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the lack of stemming .. fish and fishes, meowed\tmeowing\n",
    "\n",
    "# CountVectorizer can \n",
    "# - lowercase letters, \n",
    "# - disregard punctuation and \n",
    "# - stopwords, \n",
    "\n",
    "# but it can't LEMMATIZE or STEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n",
      "fish\n",
      "meow\n",
      "meow\n"
     ]
    }
   ],
   "source": [
    "# create the stemmer object\n",
    "from nltk import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "print(porter_stemmer.stem(\"fish\"))\n",
    "print(porter_stemmer.stem(\"fishes\"))\n",
    "print(porter_stemmer.stem(\"meowed\"))\n",
    "print(porter_stemmer.stem(\"meowing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Use NLTK's PorterStemmer\n",
    "def stemming_tokenizer(str_input):\n",
    "    ##note . removed and replaced by space - anything other than A-Za-z0-9\\- by \" \"\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    #to take off the numbers also: words = re.sub(r\"[^A-Za-z\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In India's iron age, the oldest scriptures of Hinduism were composed, social stratification based on caste emerged, and Buddhism and Jainism arose.1345**\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'india',\n",
       " 's',\n",
       " 'iron',\n",
       " 'age',\n",
       " 'the',\n",
       " 'oldest',\n",
       " 'scriptur',\n",
       " 'of',\n",
       " 'hinduism',\n",
       " 'were',\n",
       " 'compos',\n",
       " 'social',\n",
       " 'stratif',\n",
       " 'base',\n",
       " 'on',\n",
       " 'cast',\n",
       " 'emerg',\n",
       " 'and',\n",
       " 'buddhism',\n",
       " 'and',\n",
       " 'jainism',\n",
       " 'aros',\n",
       " '1345']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming_tokenizer(texts[1])\n",
    "\n",
    "#then converted to lower case\n",
    "#then split was made and then each word in the list stemmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the count vectorizer\n",
    "vect_cv = CountVectorizer(ngram_range=(1, 1), stop_words='english', tokenizer=stemming_tokenizer, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function stemming_tokenizer at 0x0000029D58732AE8>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train (Bow) \n",
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n",
      "['1345', '372-12', 'ad', 'age', 'aros', 'arriv', 'asia', 'base', 'bronz', 'buddhism', 'cast', 'christian', 'civilis', 'compani', 'compos', 'consolid', 'cultur', 'delhi', 'divers', 'earli', 'east', 'emerg', 'empir', 'era', 'expans', 'fell', 'follow', 'gupta', 'hinduism', 'home', 'india', 'indian', 'indu', 'influenc', 'iron', 'islam', 'jainism', 'judaism', 'kingdom', 'maurya', 'mediev', 'middl', 'modern', 'mughal', 'north', 'oldest', 'peninsular', 'place', 'polit', 'rule', 's', 'scriptur', 'sikhism', 'social', 'south', 'southeast', 'stratif', 'subcontin', 'sultan', 'took', 'unit', 'valley', 'vijayanagara', 'wa', 'zoroastrian']\n"
     ]
    }
   ],
   "source": [
    "# get all the feature/token names\n",
    "print(\"Vocabulary size: {}\".format(len(vect_cv.vocabulary_)))\n",
    "\n",
    "feature_names = vect_cv.get_feature_names()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dtm\n",
    "X_train_cv_dtm = vect_cv.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1345</th>\n",
       "      <th>372-12</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aros</th>\n",
       "      <th>arriv</th>\n",
       "      <th>asia</th>\n",
       "      <th>base</th>\n",
       "      <th>bronz</th>\n",
       "      <th>buddhism</th>\n",
       "      <th>...</th>\n",
       "      <th>southeast</th>\n",
       "      <th>stratif</th>\n",
       "      <th>subcontin</th>\n",
       "      <th>sultan</th>\n",
       "      <th>took</th>\n",
       "      <th>unit</th>\n",
       "      <th>valley</th>\n",
       "      <th>vijayanagara</th>\n",
       "      <th>wa</th>\n",
       "      <th>zoroastrian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1345  372-12  ad  age  aros  arriv  asia  base  bronz  buddhism  ...  \\\n",
       "0     0       0   0    1     0      0     0     0      1         0  ...   \n",
       "1     1       0   0    1     1      0     0     1      0         1  ...   \n",
       "2     0       0   0    0     0      0     1     0      0         0  ...   \n",
       "3     0       0   1    0     0      1     0     0      0         0  ...   \n",
       "4     0       0   0    0     0      0     0     0      0         0  ...   \n",
       "5     0       0   0    0     0      0     0     0      0         0  ...   \n",
       "6     0       1   0    0     0      0     0     0      0         0  ...   \n",
       "\n",
       "   southeast  stratif  subcontin  sultan  took  unit  valley  vijayanagara  \\\n",
       "0          0        0          1       0     0     0       1             0   \n",
       "1          0        1          0       0     0     0       0             0   \n",
       "2          1        0          0       0     1     0       0             0   \n",
       "3          0        0          0       0     0     0       0             0   \n",
       "4          0        0          0       1     0     1       0             1   \n",
       "5          0        0          0       0     0     0       0             0   \n",
       "6          0        0          0       0     0     0       0             0   \n",
       "\n",
       "   wa  zoroastrian  \n",
       "0   1            0  \n",
       "1   0            0  \n",
       "2   0            0  \n",
       "3   0            1  \n",
       "4   1            0  \n",
       "5   1            0  \n",
       "6   0            0  \n",
       "\n",
       "[7 rows x 65 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "pd.DataFrame(X_train_cv_dtm.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To take off the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i can chage the regular expression used for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_cv = CountVectorizer(token_pattern=\"\\\\b[A-Za-z][A-Za-z]+\\\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In India's iron age, the oldest scriptures of Hinduism were composed, social stratification based on caste emerged, and Buddhism and Jainism arose.1345**\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\b[A-Za-z][A-Za-z]+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cv.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adding', 'age', 'and', 'arose', 'arrived', 'asia', 'based', 'bronze', 'buddhism', 'by', 'caste', 'christianity', 'civilisation', 'company', 'composed', 'consolidations', 'culture', 'cultures', 'delhi', 'diverse', 'early', 'east', 'emerged', 'empire', 'empires', 'era', 'expansive', 'fell', 'followed', 'gupta', 'hinduism', 'home', 'in', 'india', 'indian', 'indus', 'influenced', 'iron', 'islam', 'jainism', 'judaism', 'kingdoms', 'maurya', 'medieval', 'middle', 'modern', 'mughal', 'north', 'of', 'oldest', 'on', 'peninsular', 'place', 'political', 'rule', 'scriptures', 'sikhism', 'social', 'south', 'southeast', 'stratification', 'subcontinent', 'sultanate', 'the', 'to', 'took', 'under', 'united', 'valley', 'vijayanagara', 'was', 'were', 'zoroastrianism']\n"
     ]
    }
   ],
   "source": [
    "print(vect_cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dtm\n",
    "X_train_cv_dtm = vect_cv.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adding</th>\n",
       "      <th>age</th>\n",
       "      <th>and</th>\n",
       "      <th>arose</th>\n",
       "      <th>arrived</th>\n",
       "      <th>asia</th>\n",
       "      <th>based</th>\n",
       "      <th>bronze</th>\n",
       "      <th>buddhism</th>\n",
       "      <th>by</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>took</th>\n",
       "      <th>under</th>\n",
       "      <th>united</th>\n",
       "      <th>valley</th>\n",
       "      <th>vijayanagara</th>\n",
       "      <th>was</th>\n",
       "      <th>were</th>\n",
       "      <th>zoroastrianism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adding  age  and  arose  arrived  asia  based  bronze  buddhism  by  ...  \\\n",
       "0       0    1    0      0        0     0      0       1         0   0  ...   \n",
       "1       0    1    2      1        0     0      1       0         1   0  ...   \n",
       "2       0    0    1      0        0     1      0       0         0   0  ...   \n",
       "3       1    0    2      0        1     0      0       0         0   0  ...   \n",
       "4       0    0    0      0        0     0      0       0         0   0  ...   \n",
       "5       0    0    0      0        0     0      0       0         0   1  ...   \n",
       "6       0    0    0      0        0     0      0       0         0   0  ...   \n",
       "\n",
       "   the  to  took  under  united  valley  vijayanagara  was  were  \\\n",
       "0    3   1     0      0       0       1             0    1     0   \n",
       "1    1   0     0      0       0       0             0    0     1   \n",
       "2    3   0     1      1       0       0             0    0     0   \n",
       "3    0   1     0      0       0       0             0    0     0   \n",
       "4    2   1     0      1       1       0             1    1     0   \n",
       "5    2   0     0      0       0       0             0    1     0   \n",
       "6    0   0     0      0       0       0             0    0     0   \n",
       "\n",
       "   zoroastrianism  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "\n",
       "[7 rows x 73 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "d = pd.DataFrame(X_train_cv_dtm.toarray(), columns=vect_cv.get_feature_names())\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
